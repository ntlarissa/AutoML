{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20151201.txt\r\n",
      "20151208.txt\r\n",
      "capture20110815-3.binetflow\r\n",
      "classification_CV.ipynb\r\n",
      "classification.ipynb\r\n",
      "\u001b[0m\u001b[01;34mCSV_CICIDS\u001b[0m/\r\n",
      "CV_CICIDS.ipynb\r\n",
      "CV_CTU.ipynb\r\n",
      "CV.ipynb\r\n",
      "CV_NSL.ipynb\r\n",
      "Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "\u001b[01;32mFridayCICIDS.csv\u001b[0m*\r\n",
      "\u001b[01;32mFriday-WorkingHours-Morning.pcap_ISCX.csv\u001b[0m*\r\n",
      "KDD_Classification.ipynb\r\n",
      "kddcup_corrected.csv\r\n",
      "kddcup.data.corrected.csv\r\n",
      "KDDTrain+.csv\r\n",
      "NUSW-NB15_features.csv\r\n",
      "RNN.ipynb\r\n",
      "UNSW-NB15.csv\r\n",
      "UNSW_NB15_testing-set.csv\r\n",
      "UNSW_NB15_training-set.csv\r\n",
      "UNSW_NB15_training-set_selected.csv\r\n",
      "Untitled1.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "\u001b[01;32mWednesday-workingHours.pcap_ISCX.csv\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 37000, 'Generic': 18871, 'Exploits': 11132, 'Fuzzers': 6062, 'DoS': 4089, 'Reconnaissance': 3496, 'Analysis': 677, 'Backdoor': 583, 'Shellcode': 378, 'Worms': 44})\n"
     ]
    }
   ],
   "source": [
    "def train_split(data):\n",
    "    X_train=data.drop(['attack_cat'], axis=1)\n",
    "    y_train=data['attack_cat']\n",
    "    return X_train,y_train\n",
    "\n",
    "data_train = pd.read_csv('./UNSW_NB15_training-set_selected.csv').drop([ 'id', 'label'], axis=1)\n",
    "#data_test = pd.read_csv('./UNSW_NB15_testing-set.csv').drop([ 'id', 'label'], axis=1)\n",
    "\n",
    "X_train,Y_train = train_split(data_train)\n",
    "\n",
    "#X_test,Y_test = train_split(data_test)\n",
    "\n",
    "#print(Counter(Y))\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "print(Counter(Y_train))\n",
    "#print(Counter(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 45332, 0: 37000})\n"
     ]
    }
   ],
   "source": [
    "def train_split_b(data):\n",
    "    X_train=data.drop(['label'], axis=1)\n",
    "    y_train=data['label']\n",
    "    return X_train,y_train\n",
    "\n",
    "data_train_b = pd.read_csv('./UNSW_NB15_training-set_selected.csv').drop([ 'id', 'attack_cat'], axis=1)\n",
    "#data_test = pd.read_csv('./UNSW_NB15_testing-set.csv').drop([ 'id', 'label'], axis=1)\n",
    "\n",
    "X_train_b,Y_train_b = train_split_b(data_train_b)\n",
    "#X_test,Y_test = train_split(data_test)\n",
    "\n",
    "#print(Counter(Y))\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "print(Counter(Y_train_b))\n",
    "#print(Counter(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82332, 151)\n",
      "(82332, 39)\n",
      "(82332, 190)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X1 = X_train.select_dtypes(include=['object'])\n",
    "ohe = OneHotEncoder()\n",
    "X1_ohe = pd.DataFrame(ohe.fit_transform(X1).toarray())\n",
    "\n",
    "print(X1_ohe.shape)\n",
    "\n",
    "X2 = X_train.select_dtypes(exclude=['object'])\n",
    "sc = StandardScaler()\n",
    "X2_sc = pd.DataFrame(sc.fit_transform(X2))\n",
    "print(X2_sc.shape)\n",
    "\n",
    "X_train_sc1 = pd.concat([X1_ohe,X2_sc], axis=1, sort=False)\n",
    "print(X_train_sc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82332, 151)\n",
      "(82332, 39)\n",
      "(82332, 190)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X1_b = X_train_b.select_dtypes(include=['object'])\n",
    "ohe = OneHotEncoder()\n",
    "X1_ohe_b = pd.DataFrame(ohe.fit_transform(X1_b).toarray())\n",
    "\n",
    "print(X1_ohe_b.shape)\n",
    "\n",
    "X2_b = X_train_b.select_dtypes(exclude=['object'])\n",
    "sc_b = StandardScaler()\n",
    "X2_sc_b = pd.DataFrame(sc_b.fit_transform(X2_b))\n",
    "print(X2_sc_b.shape)\n",
    "\n",
    "X_train_sc1_b = pd.concat([X1_ohe_b,X2_sc_b], axis=1, sort=False)\n",
    "print(X_train_sc1_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 33266, 5: 16986, 3: 10048, 4: 5424, 2: 3703, 7: 3142, 0: 615, 1: 528, 8: 345, 9: 41})\n",
      "Counter({6: 3734, 5: 1885, 3: 1084, 4: 638, 2: 386, 7: 354, 0: 62, 1: 55, 8: 33, 9: 3})\n"
     ]
    }
   ],
   "source": [
    "#instanciation\n",
    "sc = StandardScaler()\n",
    "#X_train_sc = sc.fit_transform(X_train)\n",
    "#X_test_sc = sc.fit_transform(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y_train_1 = encoder.fit_transform(Y_train)\n",
    "#Y_test_en = encoder.transform(Y_test)\n",
    "\n",
    "X_train_sc, X_test_sc, Y_train_en, Y_test_en = train_test_split(X_train_sc1, Y_train_1, test_size=0.1)\n",
    "print(Counter(Y_train_en))\n",
    "print(Counter(Y_test_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 40835, 0: 33263})\n",
      "Counter({1: 4497, 0: 3737})\n"
     ]
    }
   ],
   "source": [
    "Y_train_1_b = Y_train_b\n",
    "#Y_test_en = encoder.transform(Y_test)\n",
    "\n",
    "X_train_sc_b, X_test_sc_b, Y_train_en_b, Y_test_en_b = train_test_split(X_train_sc1_b, Y_train_1_b, test_size=0.1)\n",
    "print(Counter(Y_train_en_b))\n",
    "print(Counter(Y_test_en_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=10,input_dim=190, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=10,input_dim=190, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "74098/74098 [==============================] - 12s 169us/sample - loss: 0.7352 - acc: 0.7497\n",
      "Epoch 2/150\n",
      "74098/74098 [==============================] - 12s 162us/sample - loss: 0.5776 - acc: 0.7934\n",
      "Epoch 3/150\n",
      "74098/74098 [==============================] - 10s 128us/sample - loss: 0.5558 - acc: 0.8020\n",
      "Epoch 4/150\n",
      "74098/74098 [==============================] - 8s 113us/sample - loss: 0.5450 - acc: 0.8067\n",
      "Epoch 5/150\n",
      "74098/74098 [==============================] - 9s 122us/sample - loss: 0.5384 - acc: 0.8089\n",
      "Epoch 6/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.5332 - acc: 0.8123\n",
      "Epoch 7/150\n",
      "74098/74098 [==============================] - 13s 178us/sample - loss: 0.5298 - acc: 0.8132\n",
      "Epoch 8/150\n",
      "74098/74098 [==============================] - 15s 202us/sample - loss: 0.5268 - acc: 0.8151\n",
      "Epoch 9/150\n",
      "74098/74098 [==============================] - 13s 178us/sample - loss: 0.5241 - acc: 0.8161\n",
      "Epoch 10/150\n",
      "74098/74098 [==============================] - 12s 168us/sample - loss: 0.5214 - acc: 0.8182\n",
      "Epoch 11/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.5199 - acc: 0.8186\n",
      "Epoch 12/150\n",
      "74098/74098 [==============================] - 13s 173us/sample - loss: 0.5181 - acc: 0.8201\n",
      "Epoch 13/150\n",
      "74098/74098 [==============================] - 11s 153us/sample - loss: 0.5168 - acc: 0.8195\n",
      "Epoch 14/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.5154 - acc: 0.8213\n",
      "Epoch 15/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5145 - acc: 0.8212\n",
      "Epoch 16/150\n",
      "74098/74098 [==============================] - 11s 151us/sample - loss: 0.5130 - acc: 0.8218\n",
      "Epoch 17/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5125 - acc: 0.8223\n",
      "Epoch 18/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.5110 - acc: 0.8230\n",
      "Epoch 19/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5104 - acc: 0.8229\n",
      "Epoch 20/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.5097 - acc: 0.8238\n",
      "Epoch 21/150\n",
      "74098/74098 [==============================] - 12s 156us/sample - loss: 0.5084 - acc: 0.8244\n",
      "Epoch 22/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.5082 - acc: 0.8251\n",
      "Epoch 23/150\n",
      "74098/74098 [==============================] - 12s 156us/sample - loss: 0.5074 - acc: 0.8253\n",
      "Epoch 24/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.5067 - acc: 0.8252\n",
      "Epoch 25/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.5065 - acc: 0.8255\n",
      "Epoch 26/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.5057 - acc: 0.8261\n",
      "Epoch 27/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.5053 - acc: 0.8253\n",
      "Epoch 28/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.5047 - acc: 0.8255\n",
      "Epoch 29/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.5046 - acc: 0.8253\n",
      "Epoch 30/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5041 - acc: 0.8262\n",
      "Epoch 31/150\n",
      "74098/74098 [==============================] - 11s 153us/sample - loss: 0.5039 - acc: 0.8264\n",
      "Epoch 32/150\n",
      "74098/74098 [==============================] - 16s 214us/sample - loss: 0.5038 - acc: 0.8260\n",
      "Epoch 33/150\n",
      "74098/74098 [==============================] - 15s 208us/sample - loss: 0.5035 - acc: 0.8265\n",
      "Epoch 34/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.5029 - acc: 0.8269\n",
      "Epoch 35/150\n",
      "74098/74098 [==============================] - 14s 184us/sample - loss: 0.5028 - acc: 0.8263\n",
      "Epoch 36/150\n",
      "74098/74098 [==============================] - 15s 199us/sample - loss: 0.5024 - acc: 0.8274\n",
      "Epoch 37/150\n",
      "74098/74098 [==============================] - 16s 211us/sample - loss: 0.5021 - acc: 0.8273\n",
      "Epoch 38/150\n",
      "74098/74098 [==============================] - 14s 191us/sample - loss: 0.5019 - acc: 0.8268\n",
      "Epoch 39/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5013 - acc: 0.8274\n",
      "Epoch 40/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.5014 - acc: 0.8270\n",
      "Epoch 41/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5009 - acc: 0.8277\n",
      "Epoch 42/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.5008 - acc: 0.8275\n",
      "Epoch 43/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.5006 - acc: 0.8280\n",
      "Epoch 44/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.5005 - acc: 0.8275\n",
      "Epoch 45/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5004 - acc: 0.8280\n",
      "Epoch 46/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.5000 - acc: 0.8280\n",
      "Epoch 47/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4999 - acc: 0.8275\n",
      "Epoch 48/150\n",
      "74098/74098 [==============================] - 11s 154us/sample - loss: 0.4997 - acc: 0.8283\n",
      "Epoch 49/150\n",
      "74098/74098 [==============================] - 15s 202us/sample - loss: 0.4997 - acc: 0.8287\n",
      "Epoch 50/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.4993 - acc: 0.8277\n",
      "Epoch 51/150\n",
      "74098/74098 [==============================] - 14s 183us/sample - loss: 0.4994 - acc: 0.8279\n",
      "Epoch 52/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.4991 - acc: 0.8288\n",
      "Epoch 53/150\n",
      "74098/74098 [==============================] - 12s 167us/sample - loss: 0.4993 - acc: 0.8285\n",
      "Epoch 54/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4991 - acc: 0.8283\n",
      "Epoch 55/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.4991 - acc: 0.8287\n",
      "Epoch 56/150\n",
      "74098/74098 [==============================] - 10s 141us/sample - loss: 0.4986 - acc: 0.8289\n",
      "Epoch 57/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4982 - acc: 0.8291\n",
      "Epoch 58/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.4986 - acc: 0.8291\n",
      "Epoch 59/150\n",
      "74098/74098 [==============================] - 11s 151us/sample - loss: 0.4981 - acc: 0.8290\n",
      "Epoch 60/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4981 - acc: 0.8288\n",
      "Epoch 61/150\n",
      "74098/74098 [==============================] - 11s 155us/sample - loss: 0.4979 - acc: 0.8291\n",
      "Epoch 62/150\n",
      "74098/74098 [==============================] - 11s 153us/sample - loss: 0.4979 - acc: 0.8289\n",
      "Epoch 63/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4975 - acc: 0.8291\n",
      "Epoch 64/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4974 - acc: 0.8284\n",
      "Epoch 65/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.4975 - acc: 0.8282\n",
      "Epoch 66/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4977 - acc: 0.8289\n",
      "Epoch 67/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4977 - acc: 0.8287\n",
      "Epoch 68/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.4974 - acc: 0.8292\n",
      "Epoch 69/150\n",
      "74098/74098 [==============================] - 13s 176us/sample - loss: 0.4971 - acc: 0.8289\n",
      "Epoch 70/150\n",
      "74098/74098 [==============================] - 10s 138us/sample - loss: 0.4971 - acc: 0.8295\n",
      "Epoch 71/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4972 - acc: 0.8290\n",
      "Epoch 72/150\n",
      "74098/74098 [==============================] - 12s 156us/sample - loss: 0.4971 - acc: 0.8293\n",
      "Epoch 73/150\n",
      "74098/74098 [==============================] - 13s 173us/sample - loss: 0.4968 - acc: 0.8296\n",
      "Epoch 74/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.4965 - acc: 0.8283\n",
      "Epoch 75/150\n",
      "74098/74098 [==============================] - 16s 213us/sample - loss: 0.4969 - acc: 0.8290\n",
      "Epoch 76/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.4966 - acc: 0.8293\n",
      "Epoch 77/150\n",
      "74098/74098 [==============================] - 14s 182us/sample - loss: 0.4965 - acc: 0.8293\n",
      "Epoch 78/150\n",
      "74098/74098 [==============================] - 14s 183us/sample - loss: 0.4964 - acc: 0.8290\n",
      "Epoch 79/150\n",
      "74098/74098 [==============================] - 14s 194us/sample - loss: 0.4964 - acc: 0.8289\n",
      "Epoch 80/150\n",
      "74098/74098 [==============================] - 15s 198us/sample - loss: 0.4961 - acc: 0.8293\n",
      "Epoch 81/150\n",
      "74098/74098 [==============================] - 13s 177us/sample - loss: 0.4964 - acc: 0.8297\n",
      "Epoch 82/150\n",
      "74098/74098 [==============================] - 14s 188us/sample - loss: 0.4962 - acc: 0.8292\n",
      "Epoch 83/150\n",
      "74098/74098 [==============================] - 12s 160us/sample - loss: 0.4960 - acc: 0.8298\n",
      "Epoch 84/150\n",
      "74098/74098 [==============================] - 11s 154us/sample - loss: 0.4962 - acc: 0.8296\n",
      "Epoch 85/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.4961 - acc: 0.8292\n",
      "Epoch 86/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.4962 - acc: 0.8295\n",
      "Epoch 87/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4959 - acc: 0.8301\n",
      "Epoch 88/150\n",
      "74098/74098 [==============================] - 14s 190us/sample - loss: 0.4956 - acc: 0.8300\n",
      "Epoch 89/150\n",
      "74098/74098 [==============================] - 11s 154us/sample - loss: 0.4961 - acc: 0.8297\n",
      "Epoch 90/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4959 - acc: 0.8301\n",
      "Epoch 91/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4957 - acc: 0.8301\n",
      "Epoch 92/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4958 - acc: 0.8293\n",
      "Epoch 93/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4955 - acc: 0.8302\n",
      "Epoch 94/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4954 - acc: 0.8300\n",
      "Epoch 95/150\n",
      "74098/74098 [==============================] - 11s 153us/sample - loss: 0.4956 - acc: 0.8292\n",
      "Epoch 96/150\n",
      "74098/74098 [==============================] - 11s 151us/sample - loss: 0.4950 - acc: 0.8306\n",
      "Epoch 97/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.4953 - acc: 0.8302\n",
      "Epoch 98/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4955 - acc: 0.8298\n",
      "Epoch 99/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.4953 - acc: 0.8292\n",
      "Epoch 100/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.4954 - acc: 0.8294\n",
      "Epoch 101/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4952 - acc: 0.8293\n",
      "Epoch 102/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.4949 - acc: 0.8308\n",
      "Epoch 103/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4950 - acc: 0.8299\n",
      "Epoch 104/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.4949 - acc: 0.8298\n",
      "Epoch 105/150\n",
      "74098/74098 [==============================] - 11s 142us/sample - loss: 0.4951 - acc: 0.8305\n",
      "Epoch 106/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.4950 - acc: 0.8307\n",
      "Epoch 107/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.4951 - acc: 0.8300\n",
      "Epoch 108/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.4949 - acc: 0.8295\n",
      "Epoch 109/150\n",
      "74098/74098 [==============================] - 11s 155us/sample - loss: 0.4950 - acc: 0.8303\n",
      "Epoch 110/150\n",
      "74098/74098 [==============================] - 11s 151us/sample - loss: 0.4949 - acc: 0.8300\n",
      "Epoch 111/150\n",
      "74098/74098 [==============================] - 14s 189us/sample - loss: 0.4949 - acc: 0.8299\n",
      "Epoch 112/150\n",
      "74098/74098 [==============================] - 14s 192us/sample - loss: 0.4946 - acc: 0.8298\n",
      "Epoch 113/150\n",
      "74098/74098 [==============================] - 14s 191us/sample - loss: 0.4945 - acc: 0.8301\n",
      "Epoch 114/150\n",
      "74098/74098 [==============================] - 16s 215us/sample - loss: 0.4949 - acc: 0.8305\n",
      "Epoch 115/150\n",
      "74098/74098 [==============================] - 15s 196us/sample - loss: 0.4948 - acc: 0.8301\n",
      "Epoch 116/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.4944 - acc: 0.8298\n",
      "Epoch 117/150\n",
      "74098/74098 [==============================] - 15s 199us/sample - loss: 0.4944 - acc: 0.8296\n",
      "Epoch 118/150\n",
      "74098/74098 [==============================] - 13s 181us/sample - loss: 0.4945 - acc: 0.8304\n",
      "Epoch 119/150\n",
      "74098/74098 [==============================] - 15s 196us/sample - loss: 0.4946 - acc: 0.8297\n",
      "Epoch 120/150\n",
      "74098/74098 [==============================] - 13s 174us/sample - loss: 0.4946 - acc: 0.8303\n",
      "Epoch 121/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.4944 - acc: 0.8302\n",
      "Epoch 122/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.4945 - acc: 0.8304\n",
      "Epoch 123/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.4943 - acc: 0.8300\n",
      "Epoch 124/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.4941 - acc: 0.8303\n",
      "Epoch 125/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.4944 - acc: 0.8300\n",
      "Epoch 126/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.4943 - acc: 0.8305\n",
      "Epoch 127/150\n",
      "74098/74098 [==============================] - 13s 177us/sample - loss: 0.4939 - acc: 0.8303\n",
      "Epoch 128/150\n",
      "74098/74098 [==============================] - 19s 255us/sample - loss: 0.4945 - acc: 0.8301\n",
      "Epoch 129/150\n",
      "74098/74098 [==============================] - 18s 247us/sample - loss: 0.4941 - acc: 0.8308\n",
      "Epoch 130/150\n",
      "74098/74098 [==============================] - 19s 251us/sample - loss: 0.4941 - acc: 0.8304\n",
      "Epoch 131/150\n",
      "74098/74098 [==============================] - 18s 247us/sample - loss: 0.4941 - acc: 0.8296\n",
      "Epoch 132/150\n",
      "74098/74098 [==============================] - 20s 265us/sample - loss: 0.4939 - acc: 0.8306\n",
      "Epoch 133/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.4939 - acc: 0.8303\n",
      "Epoch 134/150\n",
      "74098/74098 [==============================] - 21s 283us/sample - loss: 0.4940 - acc: 0.8308\n",
      "Epoch 135/150\n",
      "74098/74098 [==============================] - 19s 261us/sample - loss: 0.4941 - acc: 0.8306\n",
      "Epoch 136/150\n",
      "74098/74098 [==============================] - 18s 238us/sample - loss: 0.4938 - acc: 0.8307\n",
      "Epoch 137/150\n",
      "74098/74098 [==============================] - 18s 239us/sample - loss: 0.4941 - acc: 0.8303 - loss: 0.4938 - acc: 0.830\n",
      "Epoch 138/150\n",
      "74098/74098 [==============================] - 17s 226us/sample - loss: 0.4936 - acc: 0.8307\n",
      "Epoch 139/150\n",
      "74098/74098 [==============================] - 18s 243us/sample - loss: 0.4937 - acc: 0.8304\n",
      "Epoch 140/150\n",
      "74098/74098 [==============================] - 16s 222us/sample - loss: 0.4940 - acc: 0.8303\n",
      "Epoch 141/150\n",
      "74098/74098 [==============================] - 18s 247us/sample - loss: 0.4937 - acc: 0.8309\n",
      "Epoch 142/150\n",
      "74098/74098 [==============================] - 18s 238us/sample - loss: 0.4939 - acc: 0.8299\n",
      "Epoch 143/150\n",
      "74098/74098 [==============================] - 18s 243us/sample - loss: 0.4935 - acc: 0.8307\n",
      "Epoch 144/150\n",
      "74098/74098 [==============================] - 17s 233us/sample - loss: 0.4936 - acc: 0.8299\n",
      "Epoch 145/150\n",
      "74098/74098 [==============================] - 19s 263us/sample - loss: 0.4936 - acc: 0.8307\n",
      "Epoch 146/150\n",
      "74098/74098 [==============================] - 18s 238us/sample - loss: 0.4935 - acc: 0.8301\n",
      "Epoch 147/150\n",
      "74098/74098 [==============================] - 19s 251us/sample - loss: 0.4934 - acc: 0.8302 - loss: 0.4930 - acc: 0.830\n",
      "Epoch 148/150\n",
      "74098/74098 [==============================] - 17s 231us/sample - loss: 0.4936 - acc: 0.8305\n",
      "Epoch 149/150\n",
      "74098/74098 [==============================] - 17s 231us/sample - loss: 0.4936 - acc: 0.8301\n",
      "Epoch 150/150\n",
      "74098/74098 [==============================] - 17s 226us/sample - loss: 0.4932 - acc: 0.8309 - loss: 0.4939 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb81ecba128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sc, Y_train_en, epochs=150,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "74098/74098 [==============================] - 16s 211us/sample - loss: 0.3691 - acc: 0.8529\n",
      "Epoch 2/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.2295 - acc: 0.8986\n",
      "Epoch 3/150\n",
      "74098/74098 [==============================] - 16s 214us/sample - loss: 0.2191 - acc: 0.9051\n",
      "Epoch 4/150\n",
      "74098/74098 [==============================] - 15s 209us/sample - loss: 0.2146 - acc: 0.9071\n",
      "Epoch 5/150\n",
      "74098/74098 [==============================] - 15s 205us/sample - loss: 0.2121 - acc: 0.9096\n",
      "Epoch 6/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.2101 - acc: 0.9107\n",
      "Epoch 7/150\n",
      "74098/74098 [==============================] - 14s 193us/sample - loss: 0.2089 - acc: 0.9118\n",
      "Epoch 8/150\n",
      "74098/74098 [==============================] - 13s 178us/sample - loss: 0.2076 - acc: 0.9130\n",
      "Epoch 9/150\n",
      "74098/74098 [==============================] - 14s 192us/sample - loss: 0.2069 - acc: 0.9136\n",
      "Epoch 10/150\n",
      "74098/74098 [==============================] - 13s 177us/sample - loss: 0.2062 - acc: 0.9138\n",
      "Epoch 11/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.2056 - acc: 0.9143\n",
      "Epoch 12/150\n",
      "74098/74098 [==============================] - 14s 191us/sample - loss: 0.2047 - acc: 0.9149\n",
      "Epoch 13/150\n",
      "74098/74098 [==============================] - 14s 196us/sample - loss: 0.2043 - acc: 0.9157\n",
      "Epoch 14/150\n",
      "74098/74098 [==============================] - 16s 213us/sample - loss: 0.2038 - acc: 0.9159\n",
      "Epoch 15/150\n",
      "74098/74098 [==============================] - 15s 205us/sample - loss: 0.2034 - acc: 0.9157\n",
      "Epoch 16/150\n",
      "74098/74098 [==============================] - 15s 200us/sample - loss: 0.2029 - acc: 0.9168\n",
      "Epoch 17/150\n",
      "74098/74098 [==============================] - 13s 171us/sample - loss: 0.2026 - acc: 0.9166\n",
      "Epoch 18/150\n",
      "74098/74098 [==============================] - 13s 182us/sample - loss: 0.2020 - acc: 0.9163\n",
      "Epoch 19/150\n",
      "74098/74098 [==============================] - 14s 183us/sample - loss: 0.2018 - acc: 0.9166\n",
      "Epoch 20/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.2013 - acc: 0.9178\n",
      "Epoch 21/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.2010 - acc: 0.9168\n",
      "Epoch 22/150\n",
      "74098/74098 [==============================] - 16s 219us/sample - loss: 0.2009 - acc: 0.9176\n",
      "Epoch 23/150\n",
      "74098/74098 [==============================] - 15s 202us/sample - loss: 0.2004 - acc: 0.9177\n",
      "Epoch 24/150\n",
      "74098/74098 [==============================] - 15s 203us/sample - loss: 0.2001 - acc: 0.9187\n",
      "Epoch 25/150\n",
      "74098/74098 [==============================] - 13s 182us/sample - loss: 0.1998 - acc: 0.9174\n",
      "Epoch 26/150\n",
      "74098/74098 [==============================] - 15s 208us/sample - loss: 0.1994 - acc: 0.9177\n",
      "Epoch 27/150\n",
      "74098/74098 [==============================] - 14s 191us/sample - loss: 0.1989 - acc: 0.9183\n",
      "Epoch 28/150\n",
      "74098/74098 [==============================] - 15s 206us/sample - loss: 0.1988 - acc: 0.9185\n",
      "Epoch 29/150\n",
      "74098/74098 [==============================] - 16s 209us/sample - loss: 0.1985 - acc: 0.9191\n",
      "Epoch 30/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.1983 - acc: 0.9198\n",
      "Epoch 31/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.1981 - acc: 0.9198\n",
      "Epoch 32/150\n",
      "74098/74098 [==============================] - 15s 198us/sample - loss: 0.1976 - acc: 0.9191\n",
      "Epoch 33/150\n",
      "74098/74098 [==============================] - 13s 176us/sample - loss: 0.1973 - acc: 0.9197\n",
      "Epoch 34/150\n",
      "74098/74098 [==============================] - 13s 178us/sample - loss: 0.1973 - acc: 0.9199\n",
      "Epoch 35/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.1970 - acc: 0.9210\n",
      "Epoch 36/150\n",
      "74098/74098 [==============================] - 14s 194us/sample - loss: 0.1969 - acc: 0.9208\n",
      "Epoch 37/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.1968 - acc: 0.9213\n",
      "Epoch 38/150\n",
      "74098/74098 [==============================] - 15s 205us/sample - loss: 0.1965 - acc: 0.9209\n",
      "Epoch 39/150\n",
      "74098/74098 [==============================] - 15s 200us/sample - loss: 0.1963 - acc: 0.9212\n",
      "Epoch 40/150\n",
      "74098/74098 [==============================] - 16s 210us/sample - loss: 0.1961 - acc: 0.9217\n",
      "Epoch 41/150\n",
      "74098/74098 [==============================] - 15s 206us/sample - loss: 0.1962 - acc: 0.9209\n",
      "Epoch 42/150\n",
      "74098/74098 [==============================] - 14s 194us/sample - loss: 0.1960 - acc: 0.9223\n",
      "Epoch 43/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.1958 - acc: 0.9217\n",
      "Epoch 44/150\n",
      "74098/74098 [==============================] - 14s 194us/sample - loss: 0.1957 - acc: 0.9220\n",
      "Epoch 45/150\n",
      "74098/74098 [==============================] - 14s 183us/sample - loss: 0.1957 - acc: 0.9226\n",
      "Epoch 46/150\n",
      "74098/74098 [==============================] - 14s 183us/sample - loss: 0.1956 - acc: 0.9219\n",
      "Epoch 47/150\n",
      "74098/74098 [==============================] - 13s 178us/sample - loss: 0.1955 - acc: 0.9226\n",
      "Epoch 48/150\n",
      "74098/74098 [==============================] - 18s 241us/sample - loss: 0.1955 - acc: 0.9226\n",
      "Epoch 49/150\n",
      "74098/74098 [==============================] - 18s 245us/sample - loss: 0.1955 - acc: 0.9231\n",
      "Epoch 50/150\n",
      "74098/74098 [==============================] - 19s 251us/sample - loss: 0.1953 - acc: 0.9229\n",
      "Epoch 51/150\n",
      "74098/74098 [==============================] - 17s 232us/sample - loss: 0.1952 - acc: 0.9231\n",
      "Epoch 52/150\n",
      "74098/74098 [==============================] - 17s 229us/sample - loss: 0.1952 - acc: 0.9235\n",
      "Epoch 53/150\n",
      "74098/74098 [==============================] - 16s 212us/sample - loss: 0.1951 - acc: 0.9237\n",
      "Epoch 54/150\n",
      "74098/74098 [==============================] - 16s 217us/sample - loss: 0.1948 - acc: 0.9233\n",
      "Epoch 55/150\n",
      "74098/74098 [==============================] - 17s 228us/sample - loss: 0.1950 - acc: 0.9237\n",
      "Epoch 56/150\n",
      "74098/74098 [==============================] - 16s 216us/sample - loss: 0.1949 - acc: 0.9232\n",
      "Epoch 57/150\n",
      "74098/74098 [==============================] - 17s 227us/sample - loss: 0.1949 - acc: 0.9237\n",
      "Epoch 58/150\n",
      "74098/74098 [==============================] - 13s 182us/sample - loss: 0.1949 - acc: 0.9245\n",
      "Epoch 59/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.1947 - acc: 0.9235\n",
      "Epoch 60/150\n",
      "74098/74098 [==============================] - 14s 184us/sample - loss: 0.1948 - acc: 0.9237\n",
      "Epoch 61/150\n",
      "74098/74098 [==============================] - 15s 206us/sample - loss: 0.1948 - acc: 0.9237\n",
      "Epoch 62/150\n",
      "74098/74098 [==============================] - 16s 220us/sample - loss: 0.1947 - acc: 0.9238\n",
      "Epoch 63/150\n",
      "74098/74098 [==============================] - 16s 218us/sample - loss: 0.1947 - acc: 0.9236\n",
      "Epoch 64/150\n",
      "74098/74098 [==============================] - 17s 234us/sample - loss: 0.1946 - acc: 0.9235\n",
      "Epoch 65/150\n",
      "74098/74098 [==============================] - 15s 206us/sample - loss: 0.1946 - acc: 0.9244\n",
      "Epoch 66/150\n",
      "74098/74098 [==============================] - 14s 195us/sample - loss: 0.1946 - acc: 0.9242\n",
      "Epoch 67/150\n",
      "74098/74098 [==============================] - 14s 189us/sample - loss: 0.1946 - acc: 0.9245\n",
      "Epoch 68/150\n",
      "74098/74098 [==============================] - 14s 187us/sample - loss: 0.1944 - acc: 0.9245\n",
      "Epoch 69/150\n",
      "74098/74098 [==============================] - 13s 181us/sample - loss: 0.1944 - acc: 0.9248\n",
      "Epoch 70/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.1944 - acc: 0.9244\n",
      "Epoch 71/150\n",
      "74098/74098 [==============================] - 14s 188us/sample - loss: 0.1945 - acc: 0.9238\n",
      "Epoch 72/150\n",
      "74098/74098 [==============================] - 14s 188us/sample - loss: 0.1943 - acc: 0.9253\n",
      "Epoch 73/150\n",
      "74098/74098 [==============================] - 15s 205us/sample - loss: 0.1942 - acc: 0.9240\n",
      "Epoch 74/150\n",
      "74098/74098 [==============================] - 13s 179us/sample - loss: 0.1944 - acc: 0.9244\n",
      "Epoch 75/150\n",
      "74098/74098 [==============================] - 13s 180us/sample - loss: 0.1943 - acc: 0.9244\n",
      "Epoch 76/150\n",
      "74098/74098 [==============================] - 13s 181us/sample - loss: 0.1943 - acc: 0.9243\n",
      "Epoch 77/150\n",
      "74098/74098 [==============================] - 14s 186us/sample - loss: 0.1943 - acc: 0.9242\n",
      "Epoch 78/150\n",
      "74098/74098 [==============================] - 14s 192us/sample - loss: 0.1943 - acc: 0.9244\n",
      "Epoch 79/150\n",
      "74098/74098 [==============================] - 16s 215us/sample - loss: 0.1944 - acc: 0.9248\n",
      "Epoch 80/150\n",
      "74098/74098 [==============================] - 15s 201us/sample - loss: 0.1942 - acc: 0.9240\n",
      "Epoch 81/150\n",
      "74098/74098 [==============================] - 16s 211us/sample - loss: 0.1943 - acc: 0.9246\n",
      "Epoch 82/150\n",
      "74098/74098 [==============================] - 16s 213us/sample - loss: 0.1941 - acc: 0.9242\n",
      "Epoch 83/150\n",
      "74098/74098 [==============================] - 14s 182us/sample - loss: 0.1941 - acc: 0.9245\n",
      "Epoch 84/150\n",
      "74098/74098 [==============================] - 13s 173us/sample - loss: 0.1943 - acc: 0.9248\n",
      "Epoch 85/150\n",
      "74098/74098 [==============================] - 13s 174us/sample - loss: 0.1941 - acc: 0.9252\n",
      "Epoch 86/150\n",
      "74098/74098 [==============================] - 17s 227us/sample - loss: 0.1940 - acc: 0.9248\n",
      "Epoch 87/150\n",
      "74098/74098 [==============================] - 16s 213us/sample - loss: 0.1941 - acc: 0.9245\n",
      "Epoch 88/150\n",
      "74098/74098 [==============================] - 17s 229us/sample - loss: 0.1939 - acc: 0.9248\n",
      "Epoch 89/150\n",
      "74098/74098 [==============================] - 13s 179us/sample - loss: 0.1941 - acc: 0.9252\n",
      "Epoch 90/150\n",
      "74098/74098 [==============================] - 13s 172us/sample - loss: 0.1940 - acc: 0.9242\n",
      "Epoch 91/150\n",
      "74098/74098 [==============================] - 15s 204us/sample - loss: 0.1939 - acc: 0.9252\n",
      "Epoch 92/150\n",
      "74098/74098 [==============================] - 13s 171us/sample - loss: 0.1937 - acc: 0.9255\n",
      "Epoch 93/150\n",
      "74098/74098 [==============================] - 13s 173us/sample - loss: 0.1940 - acc: 0.9235\n",
      "Epoch 94/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.1940 - acc: 0.9248\n",
      "Epoch 95/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.1940 - acc: 0.9241\n",
      "Epoch 96/150\n",
      "74098/74098 [==============================] - 11s 142us/sample - loss: 0.1939 - acc: 0.9247\n",
      "Epoch 97/150\n",
      "74098/74098 [==============================] - 10s 141us/sample - loss: 0.1938 - acc: 0.9251\n",
      "Epoch 98/150\n",
      "74098/74098 [==============================] - 11s 146us/sample - loss: 0.1940 - acc: 0.9257\n",
      "Epoch 99/150\n",
      "74098/74098 [==============================] - 11s 144us/sample - loss: 0.1939 - acc: 0.9247\n",
      "Epoch 100/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.1939 - acc: 0.9255\n",
      "Epoch 101/150\n",
      "74098/74098 [==============================] - 12s 163us/sample - loss: 0.1937 - acc: 0.9247\n",
      "Epoch 102/150\n",
      "74098/74098 [==============================] - 13s 171us/sample - loss: 0.1938 - acc: 0.9251\n",
      "Epoch 103/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.1936 - acc: 0.9248\n",
      "Epoch 104/150\n",
      "74098/74098 [==============================] - 11s 142us/sample - loss: 0.1939 - acc: 0.9250\n",
      "Epoch 105/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1938 - acc: 0.9251\n",
      "Epoch 106/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.1937 - acc: 0.9257\n",
      "Epoch 107/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.1939 - acc: 0.9254\n",
      "Epoch 108/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1937 - acc: 0.9246\n",
      "Epoch 109/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.1937 - acc: 0.9250\n",
      "Epoch 110/150\n",
      "74098/74098 [==============================] - 10s 142us/sample - loss: 0.1939 - acc: 0.9251\n",
      "Epoch 111/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.1937 - acc: 0.9252\n",
      "Epoch 112/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1938 - acc: 0.9249\n",
      "Epoch 113/150\n",
      "74098/74098 [==============================] - 11s 145us/sample - loss: 0.1936 - acc: 0.9253\n",
      "Epoch 114/150\n",
      "74098/74098 [==============================] - 11s 142us/sample - loss: 0.1936 - acc: 0.9251\n",
      "Epoch 115/150\n",
      "74098/74098 [==============================] - 11s 147us/sample - loss: 0.1936 - acc: 0.9249\n",
      "Epoch 116/150\n",
      "74098/74098 [==============================] - 10s 134us/sample - loss: 0.1936 - acc: 0.9248\n",
      "Epoch 117/150\n",
      "74098/74098 [==============================] - 10s 137us/sample - loss: 0.1934 - acc: 0.9244\n",
      "Epoch 118/150\n",
      "74098/74098 [==============================] - 10s 135us/sample - loss: 0.1936 - acc: 0.9255\n",
      "Epoch 119/150\n",
      "74098/74098 [==============================] - 10s 136us/sample - loss: 0.1937 - acc: 0.9258\n",
      "Epoch 120/150\n",
      "74098/74098 [==============================] - 10s 137us/sample - loss: 0.1934 - acc: 0.9257\n",
      "Epoch 121/150\n",
      "74098/74098 [==============================] - 10s 136us/sample - loss: 0.1936 - acc: 0.9256\n",
      "Epoch 122/150\n",
      "74098/74098 [==============================] - 10s 130us/sample - loss: 0.1936 - acc: 0.9257\n",
      "Epoch 123/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1936 - acc: 0.9254\n",
      "Epoch 124/150\n",
      "74098/74098 [==============================] - 11s 150us/sample - loss: 0.1936 - acc: 0.9252\n",
      "Epoch 125/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.1935 - acc: 0.9254\n",
      "Epoch 126/150\n",
      "74098/74098 [==============================] - 11s 154us/sample - loss: 0.1934 - acc: 0.9258\n",
      "Epoch 127/150\n",
      "74098/74098 [==============================] - 13s 171us/sample - loss: 0.1936 - acc: 0.9255\n",
      "Epoch 128/150\n",
      "74098/74098 [==============================] - 12s 165us/sample - loss: 0.1934 - acc: 0.9257\n",
      "Epoch 129/150\n",
      "74098/74098 [==============================] - 13s 171us/sample - loss: 0.1933 - acc: 0.9252\n",
      "Epoch 130/150\n",
      "74098/74098 [==============================] - 12s 160us/sample - loss: 0.1934 - acc: 0.9249\n",
      "Epoch 131/150\n",
      "74098/74098 [==============================] - 11s 144us/sample - loss: 0.1936 - acc: 0.9255\n",
      "Epoch 132/150\n",
      "74098/74098 [==============================] - 9s 124us/sample - loss: 0.1935 - acc: 0.9250\n",
      "Epoch 133/150\n",
      "74098/74098 [==============================] - 9s 120us/sample - loss: 0.1934 - acc: 0.9252\n",
      "Epoch 134/150\n",
      "74098/74098 [==============================] - 9s 120us/sample - loss: 0.1935 - acc: 0.9255\n",
      "Epoch 135/150\n",
      "74098/74098 [==============================] - 9s 124us/sample - loss: 0.1934 - acc: 0.9254\n",
      "Epoch 136/150\n",
      "74098/74098 [==============================] - 9s 117us/sample - loss: 0.1932 - acc: 0.9255\n",
      "Epoch 137/150\n",
      "74098/74098 [==============================] - 9s 115us/sample - loss: 0.1934 - acc: 0.9253\n",
      "Epoch 138/150\n",
      "74098/74098 [==============================] - 10s 134us/sample - loss: 0.1934 - acc: 0.9246\n",
      "Epoch 139/150\n",
      "74098/74098 [==============================] - 10s 131us/sample - loss: 0.1933 - acc: 0.9250\n",
      "Epoch 140/150\n",
      "74098/74098 [==============================] - 11s 143us/sample - loss: 0.1932 - acc: 0.9253\n",
      "Epoch 141/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1935 - acc: 0.9256\n",
      "Epoch 142/150\n",
      "74098/74098 [==============================] - 10s 139us/sample - loss: 0.1933 - acc: 0.9252\n",
      "Epoch 143/150\n",
      "74098/74098 [==============================] - 10s 136us/sample - loss: 0.1934 - acc: 0.9254\n",
      "Epoch 144/150\n",
      "74098/74098 [==============================] - 10s 140us/sample - loss: 0.1934 - acc: 0.9257\n",
      "Epoch 145/150\n",
      "74098/74098 [==============================] - 10s 130us/sample - loss: 0.1932 - acc: 0.9252\n",
      "Epoch 146/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.1933 - acc: 0.9247\n",
      "Epoch 147/150\n",
      "74098/74098 [==============================] - 11s 152us/sample - loss: 0.1932 - acc: 0.9247\n",
      "Epoch 148/150\n",
      "74098/74098 [==============================] - 11s 149us/sample - loss: 0.1932 - acc: 0.9256\n",
      "Epoch 149/150\n",
      "74098/74098 [==============================] - 11s 148us/sample - loss: 0.1931 - acc: 0.9252\n",
      "Epoch 150/150\n",
      "74098/74098 [==============================] - 11s 151us/sample - loss: 0.1935 - acc: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7f3566128>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit(X_train_sc_b, Y_train_en_b, epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 6, ..., 5, 3, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predSimple = model.predict_classes(X_test_sc)\n",
    "predSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predSimple_b = model_b.predict_classes(X_test_sc_b)\n",
    "predSimple_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 6, ..., 5, 3, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19469    1\n",
       "55409    1\n",
       "12680    1\n",
       "32986    0\n",
       "37773    0\n",
       "12584    1\n",
       "17617    1\n",
       "37680    0\n",
       "16387    1\n",
       "76618    0\n",
       "6225     1\n",
       "60215    1\n",
       "46130    1\n",
       "66868    0\n",
       "7411     1\n",
       "41233    0\n",
       "81504    0\n",
       "1715     1\n",
       "51445    1\n",
       "4740     1\n",
       "60668    1\n",
       "55894    1\n",
       "16179    1\n",
       "42755    0\n",
       "31121    0\n",
       "74213    0\n",
       "68400    0\n",
       "16462    1\n",
       "6913     1\n",
       "78443    0\n",
       "        ..\n",
       "12688    1\n",
       "70830    0\n",
       "12456    1\n",
       "32777    0\n",
       "66664    0\n",
       "31854    0\n",
       "81656    0\n",
       "3138     1\n",
       "14229    1\n",
       "79766    0\n",
       "58704    1\n",
       "35236    0\n",
       "35913    0\n",
       "72746    0\n",
       "5022     1\n",
       "61877    1\n",
       "1365     1\n",
       "62717    1\n",
       "62762    1\n",
       "23572    0\n",
       "42555    0\n",
       "58850    1\n",
       "73497    0\n",
       "57947    1\n",
       "45289    1\n",
       "13732    1\n",
       "30644    0\n",
       "17609    1\n",
       "215      0\n",
       "55538    1\n",
       "Name: label, Length: 8234, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_en_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8177070682535827\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,predSimple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9296818071411221\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en_b,predSimple_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul75_b = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=143, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=107, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=80, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=60, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=45, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=34, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=25, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=18, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=14, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul75 = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=143, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=107, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=80, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=60, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=45, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=34, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=25, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=18, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=14, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul75.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul75_b.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74098/74098 [==============================] - 66s 887us/sample - loss: 1.5865 - acc: 0.4454\n",
      "Epoch 2/100\n",
      "74098/74098 [==============================] - 66s 886us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 3/100\n",
      "74098/74098 [==============================] - 65s 873us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 4/100\n",
      "74098/74098 [==============================] - ETA: 0s - loss: 1.5459 - acc: 0.449 - 63s 853us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 5/100\n",
      "74098/74098 [==============================] - 64s 864us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 6/100\n",
      "74098/74098 [==============================] - 64s 870us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 7/100\n",
      "74098/74098 [==============================] - 64s 863us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 8/100\n",
      "74098/74098 [==============================] - 64s 863us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 9/100\n",
      "74098/74098 [==============================] - 63s 848us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 10/100\n",
      "74098/74098 [==============================] - 65s 878us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 11/100\n",
      "74098/74098 [==============================] - 66s 890us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 12/100\n",
      "74098/74098 [==============================] - 72s 972us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 13/100\n",
      "74098/74098 [==============================] - 70s 951us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 14/100\n",
      "74098/74098 [==============================] - 82s 1ms/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 15/100\n",
      "74098/74098 [==============================] - 66s 893us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 16/100\n",
      "74098/74098 [==============================] - 64s 867us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 17/100\n",
      "74098/74098 [==============================] - 64s 857us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 18/100\n",
      "74098/74098 [==============================] - 64s 859us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 19/100\n",
      "74098/74098 [==============================] - 67s 906us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 20/100\n",
      "74098/74098 [==============================] - 64s 869us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 21/100\n",
      "74098/74098 [==============================] - 64s 864us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 22/100\n",
      "74098/74098 [==============================] - 65s 882us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 23/100\n",
      "74098/74098 [==============================] - 67s 910us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 24/100\n",
      "74098/74098 [==============================] - 50s 670us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 25/100\n",
      "74098/74098 [==============================] - 56s 752us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 26/100\n",
      "74098/74098 [==============================] - 46s 622us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 27/100\n",
      "74098/74098 [==============================] - 35s 478us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 28/100\n",
      "74098/74098 [==============================] - 36s 480us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 29/100\n",
      "74098/74098 [==============================] - 35s 474us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 30/100\n",
      "74098/74098 [==============================] - 34s 458us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 31/100\n",
      "74098/74098 [==============================] - 39s 526us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 32/100\n",
      "74098/74098 [==============================] - 46s 624us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 33/100\n",
      "74098/74098 [==============================] - 42s 564us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 34/100\n",
      "74098/74098 [==============================] - 41s 556us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 35/100\n",
      "74098/74098 [==============================] - 41s 559us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 36/100\n",
      "74098/74098 [==============================] - 42s 570us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 37/100\n",
      "74098/74098 [==============================] - 41s 556us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 38/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 39/100\n",
      "74098/74098 [==============================] - 43s 586us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 40/100\n",
      "74098/74098 [==============================] - 42s 563us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 41/100\n",
      "74098/74098 [==============================] - 41s 549us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 42/100\n",
      "74098/74098 [==============================] - 42s 561us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 43/100\n",
      "74098/74098 [==============================] - 41s 553us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 44/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 45/100\n",
      "74098/74098 [==============================] - 41s 559us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 46/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 47/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 48/100\n",
      "74098/74098 [==============================] - 41s 557us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 49/100\n",
      "74098/74098 [==============================] - 42s 563us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 50/100\n",
      "74098/74098 [==============================] - 42s 573us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 51/100\n",
      "74098/74098 [==============================] - 42s 572us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 52/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 53/100\n",
      "74098/74098 [==============================] - 38s 516us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 54/100\n",
      "74098/74098 [==============================] - 34s 465us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 55/100\n",
      "74098/74098 [==============================] - 34s 455us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 56/100\n",
      "74098/74098 [==============================] - 34s 463us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 57/100\n",
      "74098/74098 [==============================] - 34s 463us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 58/100\n",
      "74098/74098 [==============================] - 33s 452us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 59/100\n",
      "74098/74098 [==============================] - 33s 451us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 60/100\n",
      "74098/74098 [==============================] - 34s 453us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 61/100\n",
      "74098/74098 [==============================] - 34s 456us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 62/100\n",
      "74098/74098 [==============================] - 40s 533us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 63/100\n",
      "74098/74098 [==============================] - 42s 564us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 64/100\n",
      "74098/74098 [==============================] - 38s 508us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 65/100\n",
      "74098/74098 [==============================] - 34s 453us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 66/100\n",
      "74098/74098 [==============================] - 33s 451us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 67/100\n",
      "74098/74098 [==============================] - 35s 474us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 68/100\n",
      "74098/74098 [==============================] - 34s 458us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 69/100\n",
      "74098/74098 [==============================] - 34s 460us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 70/100\n",
      "74098/74098 [==============================] - 34s 455us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 71/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 72/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 73/100\n",
      "74098/74098 [==============================] - 34s 457us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 74/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 75/100\n",
      "74098/74098 [==============================] - 40s 543us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 76/100\n",
      "74098/74098 [==============================] - 41s 559us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 77/100\n",
      "74098/74098 [==============================] - 41s 558us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74098/74098 [==============================] - 42s 569us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 79/100\n",
      "74098/74098 [==============================] - 39s 524us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 80/100\n",
      "74098/74098 [==============================] - 36s 486us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 81/100\n",
      "74098/74098 [==============================] - 42s 563us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 82/100\n",
      "74098/74098 [==============================] - 42s 562us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 83/100\n",
      "74098/74098 [==============================] - 41s 552us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 84/100\n",
      "74098/74098 [==============================] - 41s 552us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 85/100\n",
      "74098/74098 [==============================] - 42s 564us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 86/100\n",
      "74098/74098 [==============================] - 42s 569us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 87/100\n",
      "74098/74098 [==============================] - 38s 517us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 88/100\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 89/100\n",
      "74098/74098 [==============================] - 33s 449us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 90/100\n",
      "74098/74098 [==============================] - 34s 462us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 91/100\n",
      "74098/74098 [==============================] - 34s 453us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 92/100\n",
      "74098/74098 [==============================] - 34s 459us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 93/100\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 94/100\n",
      "74098/74098 [==============================] - 33s 452us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 95/100\n",
      "74098/74098 [==============================] - 35s 470us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 96/100\n",
      "74098/74098 [==============================] - 34s 455us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 97/100\n",
      "74098/74098 [==============================] - 40s 542us/sample - loss: 1.5459 - acc: 0.4495\n",
      "Epoch 98/100\n",
      "74098/74098 [==============================] - 41s 555us/sample - loss: 1.5461 - acc: 0.4495\n",
      "Epoch 99/100\n",
      "74098/74098 [==============================] - 41s 547us/sample - loss: 1.5460 - acc: 0.4495\n",
      "Epoch 100/100\n",
      "74098/74098 [==============================] - 36s 480us/sample - loss: 1.5459 - acc: 0.4495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb800c7f9e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul75.fit(X_train_sc, Y_train_en, epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74098/74098 [==============================] - 33s 449us/sample - loss: 0.7897 - acc: 0.5441\n",
      "Epoch 2/100\n",
      "74098/74098 [==============================] - 36s 480us/sample - loss: 0.6885 - acc: 0.5513\n",
      "Epoch 3/100\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 4/100\n",
      "74098/74098 [==============================] - 49s 667us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 5/100\n",
      "74098/74098 [==============================] - 46s 618us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 6/100\n",
      "74098/74098 [==============================] - 59s 793us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 7/100\n",
      "74098/74098 [==============================] - 56s 756us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 8/100\n",
      "74098/74098 [==============================] - 57s 765us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 9/100\n",
      "74098/74098 [==============================] - 55s 747us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 10/100\n",
      "74098/74098 [==============================] - 61s 819us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 11/100\n",
      "74098/74098 [==============================] - 55s 749us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 12/100\n",
      "74098/74098 [==============================] - 51s 686us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 13/100\n",
      "74098/74098 [==============================] - 49s 661us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 14/100\n",
      "74098/74098 [==============================] - 52s 696us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 15/100\n",
      "74098/74098 [==============================] - 55s 736us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 16/100\n",
      "74098/74098 [==============================] - 53s 714us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 17/100\n",
      "74098/74098 [==============================] - 55s 746us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 18/100\n",
      "74098/74098 [==============================] - 65s 873us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 19/100\n",
      "74098/74098 [==============================] - 60s 814us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 20/100\n",
      "74098/74098 [==============================] - 60s 807us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 21/100\n",
      "74098/74098 [==============================] - 56s 760us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 22/100\n",
      "74098/74098 [==============================] - 47s 629us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 23/100\n",
      "74098/74098 [==============================] - 46s 622us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 24/100\n",
      "74098/74098 [==============================] - 45s 606us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 25/100\n",
      "74098/74098 [==============================] - 44s 594us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 26/100\n",
      "74098/74098 [==============================] - 47s 632us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 27/100\n",
      "74098/74098 [==============================] - 47s 635us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 28/100\n",
      "74098/74098 [==============================] - 47s 638us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 29/100\n",
      "74098/74098 [==============================] - 46s 620us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 30/100\n",
      "74098/74098 [==============================] - 45s 608us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 31/100\n",
      "74098/74098 [==============================] - 44s 587us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 32/100\n",
      "74098/74098 [==============================] - 45s 605us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 33/100\n",
      "74098/74098 [==============================] - 44s 591us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 34/100\n",
      "74098/74098 [==============================] - 44s 600us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 35/100\n",
      "74098/74098 [==============================] - 40s 536us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 36/100\n",
      "74098/74098 [==============================] - 39s 521us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 37/100\n",
      "74098/74098 [==============================] - 39s 532us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 38/100\n",
      "74098/74098 [==============================] - 43s 586us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 39/100\n",
      "74098/74098 [==============================] - 40s 543us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 40/100\n",
      "74098/74098 [==============================] - 45s 601us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 41/100\n",
      "74098/74098 [==============================] - 45s 608us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 42/100\n",
      "74098/74098 [==============================] - 45s 605us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 43/100\n",
      "74098/74098 [==============================] - 35s 477us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 44/100\n",
      "74098/74098 [==============================] - 38s 512us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 45/100\n",
      "74098/74098 [==============================] - 39s 529us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 46/100\n",
      "74098/74098 [==============================] - 38s 518us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 47/100\n",
      "74098/74098 [==============================] - 37s 504us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 48/100\n",
      "74098/74098 [==============================] - 37s 505us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 49/100\n",
      "74098/74098 [==============================] - 32s 436us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 50/100\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 51/100\n",
      "74098/74098 [==============================] - 34s 454us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 52/100\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 53/100\n",
      "74098/74098 [==============================] - 34s 453us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 54/100\n",
      "74098/74098 [==============================] - 33s 440us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 55/100\n",
      "74098/74098 [==============================] - 32s 432us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 56/100\n",
      "74098/74098 [==============================] - 32s 432us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 57/100\n",
      "74098/74098 [==============================] - 32s 433us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 58/100\n",
      "74098/74098 [==============================] - 32s 438us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 59/100\n",
      "74098/74098 [==============================] - 32s 430us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 60/100\n",
      "74098/74098 [==============================] - 32s 430us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 61/100\n",
      "74098/74098 [==============================] - 33s 447us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 62/100\n",
      "74098/74098 [==============================] - 32s 428us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 63/100\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 64/100\n",
      "74098/74098 [==============================] - 39s 522us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 65/100\n",
      "74098/74098 [==============================] - 39s 520us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 66/100\n",
      "74098/74098 [==============================] - 37s 502us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 67/100\n",
      "74098/74098 [==============================] - 39s 525us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 68/100\n",
      "74098/74098 [==============================] - 45s 610us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 69/100\n",
      "74098/74098 [==============================] - 44s 590us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 70/100\n",
      "74098/74098 [==============================] - 44s 588us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 71/100\n",
      "74098/74098 [==============================] - 45s 604us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 72/100\n",
      "74098/74098 [==============================] - 37s 505us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 73/100\n",
      "74098/74098 [==============================] - 33s 440us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 74/100\n",
      "74098/74098 [==============================] - 43s 586us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 75/100\n",
      "74098/74098 [==============================] - 48s 646us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 76/100\n",
      "74098/74098 [==============================] - 41s 547us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 77/100\n",
      "74098/74098 [==============================] - 39s 520us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 78/100\n",
      "74098/74098 [==============================] - 37s 500us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 79/100\n",
      "74098/74098 [==============================] - 39s 522us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 80/100\n",
      "74098/74098 [==============================] - 48s 650us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 81/100\n",
      "74098/74098 [==============================] - 39s 525us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 82/100\n",
      "74098/74098 [==============================] - 38s 513us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 83/100\n",
      "74098/74098 [==============================] - 38s 519us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 84/100\n",
      "74098/74098 [==============================] - 38s 511us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 85/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 86/100\n",
      "74098/74098 [==============================] - 37s 505us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 87/100\n",
      "74098/74098 [==============================] - 39s 527us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 88/100\n",
      "74098/74098 [==============================] - 38s 513us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 89/100\n",
      "74098/74098 [==============================] - 37s 503us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 90/100\n",
      "74098/74098 [==============================] - 39s 520us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 91/100\n",
      "74098/74098 [==============================] - 38s 508us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 92/100\n",
      "74098/74098 [==============================] - 38s 514us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 93/100\n",
      "74098/74098 [==============================] - 31s 424us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 94/100\n",
      "74098/74098 [==============================] - 30s 406us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 95/100\n",
      "74098/74098 [==============================] - 30s 411us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 96/100\n",
      "74098/74098 [==============================] - 30s 409us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 97/100\n",
      "74098/74098 [==============================] - 30s 403us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 98/100\n",
      "74098/74098 [==============================] - 30s 400us/sample - loss: 0.6880 - acc: 0.5513\n",
      "Epoch 99/100\n",
      "74098/74098 [==============================] - 30s 409us/sample - loss: 0.6881 - acc: 0.5513\n",
      "Epoch 100/100\n",
      "74098/74098 [==============================] - 32s 428us/sample - loss: 0.6880 - acc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7f22dbb00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul75_b.fit(X_train_sc_b, Y_train_en_b, epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul75 = modelMul75.predict_classes(X_test_sc)\n",
    "predMul75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul75_b = modelMul75_b.predict_classes(X_test_sc_b)\n",
    "predMul75_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4486276414865193\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,predMul75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5446927374301676\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en_b,predMul75_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul50 = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=95, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=47, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=23, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul50_b = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=95, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=47, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=23, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul50.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul50_b.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74098/74098 [==============================] - 36s 484us/sample - loss: 0.3388 - acc: 0.8724\n",
      "Epoch 2/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 0.3378 - acc: 0.8720\n",
      "Epoch 3/100\n",
      "74098/74098 [==============================] - 24s 325us/sample - loss: 0.3380 - acc: 0.8723\n",
      "Epoch 4/100\n",
      "74098/74098 [==============================] - 24s 318us/sample - loss: 0.3370 - acc: 0.8728\n",
      "Epoch 5/100\n",
      "74098/74098 [==============================] - 24s 317us/sample - loss: 0.3368 - acc: 0.8728\n",
      "Epoch 6/100\n",
      "74098/74098 [==============================] - 24s 319us/sample - loss: 0.3366 - acc: 0.8725\n",
      "Epoch 7/100\n",
      "74098/74098 [==============================] - 25s 344us/sample - loss: 0.3360 - acc: 0.8731\n",
      "Epoch 8/100\n",
      "74098/74098 [==============================] - 24s 318us/sample - loss: 0.3351 - acc: 0.8729\n",
      "Epoch 9/100\n",
      "74098/74098 [==============================] - 23s 313us/sample - loss: 0.3348 - acc: 0.8744\n",
      "Epoch 10/100\n",
      "74098/74098 [==============================] - 23s 307us/sample - loss: 0.3346 - acc: 0.8734\n",
      "Epoch 11/100\n",
      "74098/74098 [==============================] - 22s 303us/sample - loss: 0.3341 - acc: 0.8731\n",
      "Epoch 12/100\n",
      "74098/74098 [==============================] - 22s 299us/sample - loss: 0.3337 - acc: 0.8741\n",
      "Epoch 13/100\n",
      "74098/74098 [==============================] - 23s 313us/sample - loss: 0.3330 - acc: 0.8745\n",
      "Epoch 14/100\n",
      "74098/74098 [==============================] - 23s 310us/sample - loss: 0.3327 - acc: 0.8736\n",
      "Epoch 15/100\n",
      "74098/74098 [==============================] - 22s 292us/sample - loss: 0.3322 - acc: 0.8747\n",
      "Epoch 16/100\n",
      "74098/74098 [==============================] - 22s 301us/sample - loss: 0.3324 - acc: 0.8746\n",
      "Epoch 17/100\n",
      "74098/74098 [==============================] - 23s 309us/sample - loss: 0.3313 - acc: 0.8736\n",
      "Epoch 18/100\n",
      "74098/74098 [==============================] - 26s 353us/sample - loss: 0.3306 - acc: 0.8744\n",
      "Epoch 19/100\n",
      "74098/74098 [==============================] - 25s 336us/sample - loss: 0.3308 - acc: 0.8743\n",
      "Epoch 20/100\n",
      "74098/74098 [==============================] - 31s 418us/sample - loss: 0.3308 - acc: 0.8754\n",
      "Epoch 21/100\n",
      "74098/74098 [==============================] - 29s 390us/sample - loss: 0.3296 - acc: 0.8746\n",
      "Epoch 22/100\n",
      "74098/74098 [==============================] - 30s 406us/sample - loss: 0.3294 - acc: 0.8747\n",
      "Epoch 23/100\n",
      "74098/74098 [==============================] - 29s 392us/sample - loss: 0.3295 - acc: 0.8744\n",
      "Epoch 24/100\n",
      "74098/74098 [==============================] - 29s 394us/sample - loss: 0.3283 - acc: 0.8745\n",
      "Epoch 25/100\n",
      "74098/74098 [==============================] - 29s 396us/sample - loss: 0.3285 - acc: 0.8751\n",
      "Epoch 26/100\n",
      "74098/74098 [==============================] - 25s 344us/sample - loss: 0.3285 - acc: 0.8742\n",
      "Epoch 27/100\n",
      "74098/74098 [==============================] - 25s 340us/sample - loss: 0.3276 - acc: 0.8757\n",
      "Epoch 28/100\n",
      "74098/74098 [==============================] - 23s 316us/sample - loss: 0.3274 - acc: 0.8752\n",
      "Epoch 29/100\n",
      "74098/74098 [==============================] - 27s 359us/sample - loss: 0.3279 - acc: 0.8752\n",
      "Epoch 30/100\n",
      "74098/74098 [==============================] - 25s 332us/sample - loss: 0.3273 - acc: 0.8751\n",
      "Epoch 31/100\n",
      "74098/74098 [==============================] - 23s 313us/sample - loss: 0.3264 - acc: 0.8758\n",
      "Epoch 32/100\n",
      "74098/74098 [==============================] - 23s 311us/sample - loss: 0.3270 - acc: 0.8759\n",
      "Epoch 33/100\n",
      "74098/74098 [==============================] - 25s 335us/sample - loss: 0.3268 - acc: 0.8757\n",
      "Epoch 34/100\n",
      "74098/74098 [==============================] - 23s 304us/sample - loss: 0.3264 - acc: 0.8760\n",
      "Epoch 35/100\n",
      "74098/74098 [==============================] - 23s 315us/sample - loss: 0.3252 - acc: 0.8765\n",
      "Epoch 36/100\n",
      "74098/74098 [==============================] - 28s 371us/sample - loss: 0.3256 - acc: 0.8759\n",
      "Epoch 37/100\n",
      "74098/74098 [==============================] - 35s 468us/sample - loss: 0.3251 - acc: 0.8757\n",
      "Epoch 38/100\n",
      "74098/74098 [==============================] - 35s 466us/sample - loss: 0.3247 - acc: 0.8769\n",
      "Epoch 39/100\n",
      "74098/74098 [==============================] - 31s 424us/sample - loss: 0.3245 - acc: 0.8760\n",
      "Epoch 40/100\n",
      "74098/74098 [==============================] - 32s 438us/sample - loss: 0.3238 - acc: 0.8760\n",
      "Epoch 41/100\n",
      "74098/74098 [==============================] - 34s 459us/sample - loss: 0.3237 - acc: 0.8765\n",
      "Epoch 42/100\n",
      "74098/74098 [==============================] - 36s 493us/sample - loss: 0.3236 - acc: 0.8765\n",
      "Epoch 43/100\n",
      "74098/74098 [==============================] - 47s 628us/sample - loss: 0.3234 - acc: 0.8763\n",
      "Epoch 44/100\n",
      "74098/74098 [==============================] - 46s 622us/sample - loss: 0.3228 - acc: 0.8772\n",
      "Epoch 45/100\n",
      "74098/74098 [==============================] - 46s 618us/sample - loss: 0.3223 - acc: 0.8763\n",
      "Epoch 46/100\n",
      "74098/74098 [==============================] - 48s 641us/sample - loss: 0.3233 - acc: 0.8770\n",
      "Epoch 47/100\n",
      "74098/74098 [==============================] - 48s 645us/sample - loss: 0.3220 - acc: 0.8772\n",
      "Epoch 48/100\n",
      "74098/74098 [==============================] - 47s 634us/sample - loss: 0.3218 - acc: 0.8762\n",
      "Epoch 49/100\n",
      "74098/74098 [==============================] - 48s 651us/sample - loss: 0.3223 - acc: 0.8762\n",
      "Epoch 50/100\n",
      "74098/74098 [==============================] - 47s 633us/sample - loss: 0.3214 - acc: 0.8774\n",
      "Epoch 51/100\n",
      "74098/74098 [==============================] - 48s 646us/sample - loss: 0.3203 - acc: 0.8774\n",
      "Epoch 52/100\n",
      "74098/74098 [==============================] - 45s 603us/sample - loss: 0.3211 - acc: 0.8771\n",
      "Epoch 53/100\n",
      "74098/74098 [==============================] - 45s 609us/sample - loss: 0.3212 - acc: 0.8768\n",
      "Epoch 54/100\n",
      "74098/74098 [==============================] - 38s 510us/sample - loss: 0.3202 - acc: 0.8774\n",
      "Epoch 55/100\n",
      "74098/74098 [==============================] - 30s 399us/sample - loss: 0.3191 - acc: 0.8775\n",
      "Epoch 56/100\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 0.3199 - acc: 0.8773\n",
      "Epoch 57/100\n",
      "74098/74098 [==============================] - 27s 371us/sample - loss: 0.3196 - acc: 0.8774\n",
      "Epoch 58/100\n",
      "74098/74098 [==============================] - 28s 377us/sample - loss: 0.3190 - acc: 0.8773\n",
      "Epoch 59/100\n",
      "74098/74098 [==============================] - 26s 357us/sample - loss: 0.3187 - acc: 0.8771\n",
      "Epoch 60/100\n",
      "74098/74098 [==============================] - 37s 494us/sample - loss: 0.3181 - acc: 0.8782\n",
      "Epoch 61/100\n",
      "74098/74098 [==============================] - 28s 381us/sample - loss: 0.3187 - acc: 0.8769\n",
      "Epoch 62/100\n",
      "74098/74098 [==============================] - 32s 426us/sample - loss: 0.3177 - acc: 0.8780\n",
      "Epoch 63/100\n",
      "74098/74098 [==============================] - 32s 435us/sample - loss: 0.3174 - acc: 0.8777\n",
      "Epoch 64/100\n",
      "74098/74098 [==============================] - 31s 423us/sample - loss: 0.3178 - acc: 0.8777\n",
      "Epoch 65/100\n",
      "74098/74098 [==============================] - 31s 422us/sample - loss: 0.3169 - acc: 0.8789\n",
      "Epoch 66/100\n",
      "74098/74098 [==============================] - 32s 428us/sample - loss: 0.3166 - acc: 0.8781\n",
      "Epoch 67/100\n",
      "74098/74098 [==============================] - 32s 432us/sample - loss: 0.3163 - acc: 0.8777\n",
      "Epoch 68/100\n",
      "74098/74098 [==============================] - 31s 422us/sample - loss: 0.3159 - acc: 0.8782\n",
      "Epoch 69/100\n",
      "74098/74098 [==============================] - 31s 423us/sample - loss: 0.3162 - acc: 0.8779\n",
      "Epoch 70/100\n",
      "74098/74098 [==============================] - 44s 600us/sample - loss: 0.3158 - acc: 0.8781\n",
      "Epoch 71/100\n",
      "74098/74098 [==============================] - 36s 483us/sample - loss: 0.3153 - acc: 0.8781\n",
      "Epoch 72/100\n",
      "74098/74098 [==============================] - 26s 346us/sample - loss: 0.3153 - acc: 0.8787\n",
      "Epoch 73/100\n",
      "74098/74098 [==============================] - 26s 353us/sample - loss: 0.3148 - acc: 0.8786\n",
      "Epoch 74/100\n",
      "74098/74098 [==============================] - 28s 381us/sample - loss: 0.3146 - acc: 0.8786\n",
      "Epoch 75/100\n",
      "74098/74098 [==============================] - 31s 419us/sample - loss: 0.3136 - acc: 0.8787\n",
      "Epoch 76/100\n",
      "74098/74098 [==============================] - 27s 362us/sample - loss: 0.3144 - acc: 0.8791\n",
      "Epoch 77/100\n",
      "74098/74098 [==============================] - 25s 337us/sample - loss: 0.3135 - acc: 0.8791\n",
      "Epoch 78/100\n",
      "74098/74098 [==============================] - 27s 360us/sample - loss: 0.3139 - acc: 0.8785\n",
      "Epoch 79/100\n",
      "74098/74098 [==============================] - 26s 348us/sample - loss: 0.3120 - acc: 0.8800\n",
      "Epoch 80/100\n",
      "74098/74098 [==============================] - 31s 421us/sample - loss: 0.3127 - acc: 0.8790\n",
      "Epoch 81/100\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.3128 - acc: 0.8791\n",
      "Epoch 82/100\n",
      "74098/74098 [==============================] - 39s 523us/sample - loss: 0.3117 - acc: 0.8794\n",
      "Epoch 83/100\n",
      "74098/74098 [==============================] - 46s 624us/sample - loss: 0.3121 - acc: 0.8791\n",
      "Epoch 84/100\n",
      "74098/74098 [==============================] - 45s 611us/sample - loss: 0.3115 - acc: 0.8794\n",
      "Epoch 85/100\n",
      "74098/74098 [==============================] - 47s 629us/sample - loss: 0.3120 - acc: 0.8791\n",
      "Epoch 86/100\n",
      "74098/74098 [==============================] - 46s 624us/sample - loss: 0.3117 - acc: 0.8792\n",
      "Epoch 87/100\n",
      "74098/74098 [==============================] - 46s 627us/sample - loss: 0.3116 - acc: 0.8795\n",
      "Epoch 88/100\n",
      "74098/74098 [==============================] - 46s 619us/sample - loss: 0.3106 - acc: 0.8796\n",
      "Epoch 89/100\n",
      "74098/74098 [==============================] - 47s 635us/sample - loss: 0.3099 - acc: 0.8797\n",
      "Epoch 90/100\n",
      "74098/74098 [==============================] - 45s 604us/sample - loss: 0.3105 - acc: 0.8808\n",
      "Epoch 91/100\n",
      "74098/74098 [==============================] - 45s 609us/sample - loss: 0.3101 - acc: 0.8805\n",
      "Epoch 92/100\n",
      "74098/74098 [==============================] - 35s 466us/sample - loss: 0.3105 - acc: 0.8800\n",
      "Epoch 93/100\n",
      "74098/74098 [==============================] - 30s 398us/sample - loss: 0.3089 - acc: 0.8803\n",
      "Epoch 94/100\n",
      "74098/74098 [==============================] - 40s 541us/sample - loss: 0.3099 - acc: 0.8796\n",
      "Epoch 95/100\n",
      "74098/74098 [==============================] - 46s 621us/sample - loss: 0.3096 - acc: 0.8797\n",
      "Epoch 96/100\n",
      "74098/74098 [==============================] - 47s 638us/sample - loss: 0.3093 - acc: 0.8804\n",
      "Epoch 97/100\n",
      "74098/74098 [==============================] - 48s 654us/sample - loss: 0.3083 - acc: 0.8804\n",
      "Epoch 98/100\n",
      "74098/74098 [==============================] - 46s 620us/sample - loss: 0.3079 - acc: 0.8809\n",
      "Epoch 99/100\n",
      "74098/74098 [==============================] - 47s 631us/sample - loss: 0.3075 - acc: 0.8801\n",
      "Epoch 100/100\n",
      "74098/74098 [==============================] - 47s 634us/sample - loss: 0.3079 - acc: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7f185e9e8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul50.fit(X_train_sc, Y_train_en, epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74098/74098 [==============================] - 48s 649us/sample - loss: 0.7647 - acc: 0.5710\n",
      "Epoch 2/100\n",
      "74098/74098 [==============================] - ETA: 0s - loss: 0.4302 - acc: 0.787 - 48s 642us/sample - loss: 0.4302 - acc: 0.7872\n",
      "Epoch 3/100\n",
      "74098/74098 [==============================] - 48s 650us/sample - loss: 0.2521 - acc: 0.8882\n",
      "Epoch 4/100\n",
      "74098/74098 [==============================] - 49s 665us/sample - loss: 0.1455 - acc: 0.9440\n",
      "Epoch 5/100\n",
      "74098/74098 [==============================] - 32s 430us/sample - loss: 0.1287 - acc: 0.9503\n",
      "Epoch 6/100\n",
      "74098/74098 [==============================] - 32s 427us/sample - loss: 0.1230 - acc: 0.9523\n",
      "Epoch 7/100\n",
      "74098/74098 [==============================] - 39s 526us/sample - loss: 0.1203 - acc: 0.9526\n",
      "Epoch 8/100\n",
      "74098/74098 [==============================] - 48s 646us/sample - loss: 0.1174 - acc: 0.9542\n",
      "Epoch 9/100\n",
      "74098/74098 [==============================] - 45s 610us/sample - loss: 0.1139 - acc: 0.9549\n",
      "Epoch 10/100\n",
      "74098/74098 [==============================] - 39s 524us/sample - loss: 0.1116 - acc: 0.9561\n",
      "Epoch 11/100\n",
      "74098/74098 [==============================] - 37s 493us/sample - loss: 0.1096 - acc: 0.9559\n",
      "Epoch 12/100\n",
      "74098/74098 [==============================] - 36s 487us/sample - loss: 0.1081 - acc: 0.9565\n",
      "Epoch 13/100\n",
      "74098/74098 [==============================] - 47s 634us/sample - loss: 0.1069 - acc: 0.9570\n",
      "Epoch 14/100\n",
      "74098/74098 [==============================] - 47s 639us/sample - loss: 0.1046 - acc: 0.9580\n",
      "Epoch 15/100\n",
      "74098/74098 [==============================] - 47s 640us/sample - loss: 0.1034 - acc: 0.9587\n",
      "Epoch 16/100\n",
      "74098/74098 [==============================] - 49s 665us/sample - loss: 0.1019 - acc: 0.9590\n",
      "Epoch 17/100\n",
      "74098/74098 [==============================] - 42s 565us/sample - loss: 0.1009 - acc: 0.9594\n",
      "Epoch 18/100\n",
      "74098/74098 [==============================] - 40s 537us/sample - loss: 0.0992 - acc: 0.9594\n",
      "Epoch 19/100\n",
      "74098/74098 [==============================] - 41s 555us/sample - loss: 0.0990 - acc: 0.9599\n",
      "Epoch 20/100\n",
      "74098/74098 [==============================] - 36s 486us/sample - loss: 0.0974 - acc: 0.9602\n",
      "Epoch 21/100\n",
      "74098/74098 [==============================] - 39s 529us/sample - loss: 0.0973 - acc: 0.9613\n",
      "Epoch 22/100\n",
      "74098/74098 [==============================] - 43s 586us/sample - loss: 0.0959 - acc: 0.9611\n",
      "Epoch 23/100\n",
      "74098/74098 [==============================] - 44s 591us/sample - loss: 0.0958 - acc: 0.9617\n",
      "Epoch 24/100\n",
      "74098/74098 [==============================] - 43s 581us/sample - loss: 0.0948 - acc: 0.9614\n",
      "Epoch 25/100\n",
      "74098/74098 [==============================] - 43s 577us/sample - loss: 0.0939 - acc: 0.9620\n",
      "Epoch 26/100\n",
      "74098/74098 [==============================] - 43s 585us/sample - loss: 0.0935 - acc: 0.9619\n",
      "Epoch 27/100\n",
      "74098/74098 [==============================] - 43s 584us/sample - loss: 0.0930 - acc: 0.9623\n",
      "Epoch 28/100\n",
      "74098/74098 [==============================] - 43s 575us/sample - loss: 0.0923 - acc: 0.9628\n",
      "Epoch 29/100\n",
      "74098/74098 [==============================] - 43s 581us/sample - loss: 0.0920 - acc: 0.9629\n",
      "Epoch 30/100\n",
      "74098/74098 [==============================] - 42s 563us/sample - loss: 0.0912 - acc: 0.9633\n",
      "Epoch 31/100\n",
      "74098/74098 [==============================] - 42s 568us/sample - loss: 0.0911 - acc: 0.9628\n",
      "Epoch 32/100\n",
      "74098/74098 [==============================] - 42s 573us/sample - loss: 0.0907 - acc: 0.9638\n",
      "Epoch 33/100\n",
      "74098/74098 [==============================] - 50s 668us/sample - loss: 0.0903 - acc: 0.9631\n",
      "Epoch 34/100\n",
      "74098/74098 [==============================] - 48s 643us/sample - loss: 0.0897 - acc: 0.9640\n",
      "Epoch 35/100\n",
      "74098/74098 [==============================] - 40s 536us/sample - loss: 0.0894 - acc: 0.9643\n",
      "Epoch 36/100\n",
      "74098/74098 [==============================] - 40s 538us/sample - loss: 0.0882 - acc: 0.9645\n",
      "Epoch 37/100\n",
      "74098/74098 [==============================] - 38s 508us/sample - loss: 0.0883 - acc: 0.9646\n",
      "Epoch 38/100\n",
      "74098/74098 [==============================] - 34s 462us/sample - loss: 0.0873 - acc: 0.9647\n",
      "Epoch 39/100\n",
      "74098/74098 [==============================] - 34s 465us/sample - loss: 0.0871 - acc: 0.9646\n",
      "Epoch 40/100\n",
      "74098/74098 [==============================] - 35s 471us/sample - loss: 0.0866 - acc: 0.9656\n",
      "Epoch 41/100\n",
      "74098/74098 [==============================] - 34s 460us/sample - loss: 0.0860 - acc: 0.9656\n",
      "Epoch 42/100\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 0.0864 - acc: 0.9651\n",
      "Epoch 43/100\n",
      "74098/74098 [==============================] - 34s 456us/sample - loss: 0.0856 - acc: 0.9650\n",
      "Epoch 44/100\n",
      "74098/74098 [==============================] - 35s 473us/sample - loss: 0.0857 - acc: 0.9656\n",
      "Epoch 45/100\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.0845 - acc: 0.9665\n",
      "Epoch 46/100\n",
      "74098/74098 [==============================] - 34s 459us/sample - loss: 0.0843 - acc: 0.9661\n",
      "Epoch 47/100\n",
      "74098/74098 [==============================] - 38s 509us/sample - loss: 0.0839 - acc: 0.9665\n",
      "Epoch 48/100\n",
      "74098/74098 [==============================] - 36s 486us/sample - loss: 0.0838 - acc: 0.9659\n",
      "Epoch 49/100\n",
      "74098/74098 [==============================] - 35s 468us/sample - loss: 0.0833 - acc: 0.9664\n",
      "Epoch 50/100\n",
      "74098/74098 [==============================] - 33s 447us/sample - loss: 0.0830 - acc: 0.9672\n",
      "Epoch 51/100\n",
      "74098/74098 [==============================] - 32s 436us/sample - loss: 0.0826 - acc: 0.9672\n",
      "Epoch 52/100\n",
      "74098/74098 [==============================] - 34s 454us/sample - loss: 0.0820 - acc: 0.9668\n",
      "Epoch 53/100\n",
      "74098/74098 [==============================] - 32s 430us/sample - loss: 0.0819 - acc: 0.9667\n",
      "Epoch 54/100\n",
      "74098/74098 [==============================] - 34s 452us/sample - loss: 0.0819 - acc: 0.9672\n",
      "Epoch 55/100\n",
      "74098/74098 [==============================] - 33s 448us/sample - loss: 0.0814 - acc: 0.9671\n",
      "Epoch 56/100\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 0.0806 - acc: 0.9674\n",
      "Epoch 57/100\n",
      "74098/74098 [==============================] - 33s 442us/sample - loss: 0.0807 - acc: 0.9673\n",
      "Epoch 58/100\n",
      "74098/74098 [==============================] - 35s 475us/sample - loss: 0.0806 - acc: 0.9675\n",
      "Epoch 59/100\n",
      "74098/74098 [==============================] - 37s 495us/sample - loss: 0.0807 - acc: 0.9673\n",
      "Epoch 60/100\n",
      "74098/74098 [==============================] - 46s 627us/sample - loss: 0.0806 - acc: 0.9675\n",
      "Epoch 61/100\n",
      "74098/74098 [==============================] - 46s 621us/sample - loss: 0.0798 - acc: 0.9678\n",
      "Epoch 62/100\n",
      "74098/74098 [==============================] - 41s 555us/sample - loss: 0.0793 - acc: 0.9679\n",
      "Epoch 63/100\n",
      "74098/74098 [==============================] - 40s 536us/sample - loss: 0.0799 - acc: 0.9678\n",
      "Epoch 64/100\n",
      "74098/74098 [==============================] - 37s 494us/sample - loss: 0.0788 - acc: 0.9686\n",
      "Epoch 65/100\n",
      "74098/74098 [==============================] - 43s 578us/sample - loss: 0.0794 - acc: 0.9683\n",
      "Epoch 66/100\n",
      "74098/74098 [==============================] - 41s 552us/sample - loss: 0.0791 - acc: 0.9686\n",
      "Epoch 67/100\n",
      "74098/74098 [==============================] - 38s 516us/sample - loss: 0.0789 - acc: 0.9678\n",
      "Epoch 68/100\n",
      "74098/74098 [==============================] - 39s 522us/sample - loss: 0.0788 - acc: 0.9688\n",
      "Epoch 69/100\n",
      "74098/74098 [==============================] - 39s 533us/sample - loss: 0.0788 - acc: 0.9684\n",
      "Epoch 70/100\n",
      "74098/74098 [==============================] - 45s 602us/sample - loss: 0.0780 - acc: 0.9686\n",
      "Epoch 71/100\n",
      "74098/74098 [==============================] - 48s 643us/sample - loss: 0.0776 - acc: 0.9693\n",
      "Epoch 72/100\n",
      "74098/74098 [==============================] - 44s 591us/sample - loss: 0.0775 - acc: 0.9692\n",
      "Epoch 73/100\n",
      "74098/74098 [==============================] - 45s 604us/sample - loss: 0.0779 - acc: 0.9684\n",
      "Epoch 74/100\n",
      "74098/74098 [==============================] - 46s 615us/sample - loss: 0.0780 - acc: 0.9684\n",
      "Epoch 75/100\n",
      "74098/74098 [==============================] - 47s 630us/sample - loss: 0.0775 - acc: 0.9696\n",
      "Epoch 76/100\n",
      "74098/74098 [==============================] - 46s 614us/sample - loss: 0.0771 - acc: 0.9694\n",
      "Epoch 77/100\n",
      "74098/74098 [==============================] - 40s 541us/sample - loss: 0.0773 - acc: 0.9689\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74098/74098 [==============================] - 44s 590us/sample - loss: 0.0774 - acc: 0.9689\n",
      "Epoch 79/100\n",
      "74098/74098 [==============================] - 44s 595us/sample - loss: 0.0762 - acc: 0.9696\n",
      "Epoch 80/100\n",
      "74098/74098 [==============================] - 45s 609us/sample - loss: 0.0767 - acc: 0.9693\n",
      "Epoch 81/100\n",
      "74098/74098 [==============================] - 44s 597us/sample - loss: 0.0766 - acc: 0.9693\n",
      "Epoch 82/100\n",
      "74098/74098 [==============================] - 42s 561us/sample - loss: 0.0768 - acc: 0.9690\n",
      "Epoch 83/100\n",
      "74098/74098 [==============================] - 41s 553us/sample - loss: 0.0759 - acc: 0.9699\n",
      "Epoch 84/100\n",
      "74098/74098 [==============================] - 42s 567us/sample - loss: 0.0756 - acc: 0.9693\n",
      "Epoch 85/100\n",
      "74098/74098 [==============================] - 43s 586us/sample - loss: 0.0760 - acc: 0.9695\n",
      "Epoch 86/100\n",
      "74098/74098 [==============================] - 40s 546us/sample - loss: 0.0756 - acc: 0.9696\n",
      "Epoch 87/100\n",
      "74098/74098 [==============================] - 36s 482us/sample - loss: 0.0756 - acc: 0.9701\n",
      "Epoch 88/100\n",
      "74098/74098 [==============================] - 39s 532us/sample - loss: 0.0754 - acc: 0.9695\n",
      "Epoch 89/100\n",
      "74098/74098 [==============================] - 37s 499us/sample - loss: 0.0754 - acc: 0.9701\n",
      "Epoch 90/100\n",
      "74098/74098 [==============================] - 38s 512us/sample - loss: 0.0748 - acc: 0.9699\n",
      "Epoch 91/100\n",
      "74098/74098 [==============================] - 38s 518us/sample - loss: 0.0750 - acc: 0.9700\n",
      "Epoch 92/100\n",
      "74098/74098 [==============================] - 39s 530us/sample - loss: 0.0746 - acc: 0.9703\n",
      "Epoch 93/100\n",
      "74098/74098 [==============================] - 36s 484us/sample - loss: 0.0752 - acc: 0.9698\n",
      "Epoch 94/100\n",
      "74098/74098 [==============================] - 42s 568us/sample - loss: 0.0747 - acc: 0.9701\n",
      "Epoch 95/100\n",
      "74098/74098 [==============================] - 41s 552us/sample - loss: 0.0746 - acc: 0.9705\n",
      "Epoch 96/100\n",
      "74098/74098 [==============================] - 37s 493us/sample - loss: 0.0743 - acc: 0.9702\n",
      "Epoch 97/100\n",
      "74098/74098 [==============================] - 36s 486us/sample - loss: 0.0741 - acc: 0.9702\n",
      "Epoch 98/100\n",
      "74098/74098 [==============================] - 37s 497us/sample - loss: 0.0739 - acc: 0.9703\n",
      "Epoch 99/100\n",
      "74098/74098 [==============================] - 35s 471us/sample - loss: 0.0740 - acc: 0.9704\n",
      "Epoch 100/100\n",
      "74098/74098 [==============================] - 38s 516us/sample - loss: 0.0742 - acc: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7f11a5ef0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul50_b.fit(X_train_sc_b, Y_train_en_b, epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 6, ..., 5, 7, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul50 = modelMul50.predict_classes(X_test_sc)\n",
    "predMul50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul50_b = modelMul50_b.predict_classes(X_test_sc_b)\n",
    "predMul50_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8580276900655818\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,predMul50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696380859849405\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en_b,predMul50_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=145, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=95, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=47, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul_b = keras.Sequential([\n",
    "   # keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units=190,input_dim=190, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=145, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=95, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=47, activation=\"softmax\"),\n",
    "    keras.layers.Dense(units=1, activation=\"softmax\"),\n",
    "    #keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics={'output_a': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMul_b.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "             metrics={'output_a': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 1.1591\n",
      "Epoch 2/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 0.6366\n",
      "Epoch 3/150\n",
      "74098/74098 [==============================] - 30s 412us/sample - loss: 0.5875\n",
      "Epoch 4/150\n",
      "74098/74098 [==============================] - 36s 484us/sample - loss: 0.5580\n",
      "Epoch 5/150\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 0.5418\n",
      "Epoch 6/150\n",
      "74098/74098 [==============================] - 34s 464us/sample - loss: 0.5289\n",
      "Epoch 7/150\n",
      "74098/74098 [==============================] - 34s 462us/sample - loss: 0.5140\n",
      "Epoch 8/150\n",
      "74098/74098 [==============================] - 33s 447us/sample - loss: 0.4971\n",
      "Epoch 9/150\n",
      "74098/74098 [==============================] - 32s 438us/sample - loss: 0.4840\n",
      "Epoch 10/150\n",
      "74098/74098 [==============================] - 28s 372us/sample - loss: 0.4730\n",
      "Epoch 11/150\n",
      "74098/74098 [==============================] - 32s 429us/sample - loss: 0.4645\n",
      "Epoch 12/150\n",
      "74098/74098 [==============================] - 34s 463us/sample - loss: 0.4586\n",
      "Epoch 13/150\n",
      "74098/74098 [==============================] - 34s 465us/sample - loss: 0.4520\n",
      "Epoch 14/150\n",
      "74098/74098 [==============================] - 35s 466us/sample - loss: 0.4457\n",
      "Epoch 15/150\n",
      "74098/74098 [==============================] - 35s 466us/sample - loss: 0.4412\n",
      "Epoch 16/150\n",
      "74098/74098 [==============================] - 35s 473us/sample - loss: 0.4346\n",
      "Epoch 17/150\n",
      "74098/74098 [==============================] - 33s 446us/sample - loss: 0.4288\n",
      "Epoch 18/150\n",
      "74098/74098 [==============================] - 28s 377us/sample - loss: 0.4242\n",
      "Epoch 19/150\n",
      "74098/74098 [==============================] - 28s 379us/sample - loss: 0.4195\n",
      "Epoch 20/150\n",
      "74098/74098 [==============================] - 28s 373us/sample - loss: 0.4150\n",
      "Epoch 21/150\n",
      "74098/74098 [==============================] - 29s 387us/sample - loss: 0.4114\n",
      "Epoch 22/150\n",
      "74098/74098 [==============================] - 28s 378us/sample - loss: 0.4070\n",
      "Epoch 23/150\n",
      "74098/74098 [==============================] - 30s 402us/sample - loss: 0.4042\n",
      "Epoch 24/150\n",
      "74098/74098 [==============================] - 35s 477us/sample - loss: 0.4005\n",
      "Epoch 25/150\n",
      "74098/74098 [==============================] - 34s 461us/sample - loss: 0.3972\n",
      "Epoch 26/150\n",
      "74098/74098 [==============================] - 35s 467us/sample - loss: 0.3952\n",
      "Epoch 27/150\n",
      "74098/74098 [==============================] - 28s 384us/sample - loss: 0.3922\n",
      "Epoch 28/150\n",
      "74098/74098 [==============================] - 32s 428us/sample - loss: 0.3895\n",
      "Epoch 29/150\n",
      "74098/74098 [==============================] - 35s 473us/sample - loss: 0.3878\n",
      "Epoch 30/150\n",
      "74098/74098 [==============================] - 35s 469us/sample - loss: 0.3850\n",
      "Epoch 31/150\n",
      "74098/74098 [==============================] - 35s 468us/sample - loss: 0.3832\n",
      "Epoch 32/150\n",
      "74098/74098 [==============================] - 36s 484us/sample - loss: 0.3812\n",
      "Epoch 33/150\n",
      "74098/74098 [==============================] - 34s 460us/sample - loss: 0.3787\n",
      "Epoch 34/150\n",
      "74098/74098 [==============================] - 33s 439us/sample - loss: 0.3769\n",
      "Epoch 35/150\n",
      "74098/74098 [==============================] - 27s 368us/sample - loss: 0.3759\n",
      "Epoch 36/150\n",
      "74098/74098 [==============================] - 34s 459us/sample - loss: 0.3741\n",
      "Epoch 37/150\n",
      "74098/74098 [==============================] - 35s 475us/sample - loss: 0.3726\n",
      "Epoch 38/150\n",
      "74098/74098 [==============================] - 35s 470us/sample - loss: 0.3716\n",
      "Epoch 39/150\n",
      "74098/74098 [==============================] - 35s 477us/sample - loss: 0.3702\n",
      "Epoch 40/150\n",
      "74098/74098 [==============================] - 36s 486us/sample - loss: 0.3688\n",
      "Epoch 41/150\n",
      "74098/74098 [==============================] - 35s 476us/sample - loss: 0.3683\n",
      "Epoch 42/150\n",
      "74098/74098 [==============================] - 35s 478us/sample - loss: 0.3666\n",
      "Epoch 43/150\n",
      "74098/74098 [==============================] - 34s 465us/sample - loss: 0.3653\n",
      "Epoch 44/150\n",
      "74098/74098 [==============================] - 33s 446us/sample - loss: 0.3644\n",
      "Epoch 45/150\n",
      "74098/74098 [==============================] - 35s 470us/sample - loss: 0.3636\n",
      "Epoch 46/150\n",
      "74098/74098 [==============================] - 34s 457us/sample - loss: 0.3626\n",
      "Epoch 47/150\n",
      "74098/74098 [==============================] - 34s 463us/sample - loss: 0.3617\n",
      "Epoch 48/150\n",
      "74098/74098 [==============================] - 31s 425us/sample - loss: 0.3606\n",
      "Epoch 49/150\n",
      "74098/74098 [==============================] - 28s 382us/sample - loss: 0.3604\n",
      "Epoch 50/150\n",
      "74098/74098 [==============================] - 29s 391us/sample - loss: 0.3595\n",
      "Epoch 51/150\n",
      "74098/74098 [==============================] - 35s 477us/sample - loss: 0.3579\n",
      "Epoch 52/150\n",
      "74098/74098 [==============================] - 34s 459us/sample - loss: 0.3573\n",
      "Epoch 53/150\n",
      "74098/74098 [==============================] - 34s 463us/sample - loss: 0.3569\n",
      "Epoch 54/150\n",
      "74098/74098 [==============================] - 34s 460us/sample - loss: 0.3561\n",
      "Epoch 55/150\n",
      "74098/74098 [==============================] - 36s 479us/sample - loss: 0.3559\n",
      "Epoch 56/150\n",
      "74098/74098 [==============================] - 33s 451us/sample - loss: 0.3546\n",
      "Epoch 57/150\n",
      "74098/74098 [==============================] - 34s 455us/sample - loss: 0.3539\n",
      "Epoch 58/150\n",
      "74098/74098 [==============================] - 34s 453us/sample - loss: 0.3542\n",
      "Epoch 59/150\n",
      "74098/74098 [==============================] - 34s 457us/sample - loss: 0.3522\n",
      "Epoch 60/150\n",
      "74098/74098 [==============================] - 35s 470us/sample - loss: 0.3520\n",
      "Epoch 61/150\n",
      "74098/74098 [==============================] - 33s 450us/sample - loss: 0.3509\n",
      "Epoch 62/150\n",
      "74098/74098 [==============================] - 31s 414us/sample - loss: 0.3507\n",
      "Epoch 63/150\n",
      "74098/74098 [==============================] - 28s 378us/sample - loss: 0.3503\n",
      "Epoch 64/150\n",
      "74098/74098 [==============================] - 22s 294us/sample - loss: 0.3494\n",
      "Epoch 65/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3491\n",
      "Epoch 66/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3485\n",
      "Epoch 67/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3474\n",
      "Epoch 68/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3476\n",
      "Epoch 69/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3470\n",
      "Epoch 70/150\n",
      "74098/74098 [==============================] - 22s 294us/sample - loss: 0.3459\n",
      "Epoch 71/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3455\n",
      "Epoch 72/150\n",
      "74098/74098 [==============================] - 22s 292us/sample - loss: 0.3456\n",
      "Epoch 73/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3452\n",
      "Epoch 74/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3436\n",
      "Epoch 75/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3437\n",
      "Epoch 76/150\n",
      "74098/74098 [==============================] - 22s 294us/sample - loss: 0.3431\n",
      "Epoch 77/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3424\n",
      "Epoch 78/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3414\n",
      "Epoch 79/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3412\n",
      "Epoch 80/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3407\n",
      "Epoch 81/150\n",
      "74098/74098 [==============================] - 22s 295us/sample - loss: 0.3398\n",
      "Epoch 82/150\n",
      "74098/74098 [==============================] - 21s 284us/sample - loss: 0.3398\n",
      "Epoch 83/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3388\n",
      "Epoch 84/150\n",
      "74098/74098 [==============================] - 22s 296us/sample - loss: 0.3390\n",
      "Epoch 85/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3386\n",
      "Epoch 86/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3376\n",
      "Epoch 87/150\n",
      "74098/74098 [==============================] - 22s 292us/sample - loss: 0.3372\n",
      "Epoch 88/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3372\n",
      "Epoch 89/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3365\n",
      "Epoch 90/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3365\n",
      "Epoch 91/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3355\n",
      "Epoch 92/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3353\n",
      "Epoch 93/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3349\n",
      "Epoch 94/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3341\n",
      "Epoch 95/150\n",
      "74098/74098 [==============================] - 22s 292us/sample - loss: 0.3332\n",
      "Epoch 96/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3334\n",
      "Epoch 97/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3329\n",
      "Epoch 98/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3324\n",
      "Epoch 99/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3327\n",
      "Epoch 100/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3317\n",
      "Epoch 101/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3319\n",
      "Epoch 102/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3315\n",
      "Epoch 103/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3304\n",
      "Epoch 104/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3318\n",
      "Epoch 105/150\n",
      "74098/74098 [==============================] - 21s 283us/sample - loss: 0.3297\n",
      "Epoch 106/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3296\n",
      "Epoch 107/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3299\n",
      "Epoch 108/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3297\n",
      "Epoch 109/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3287\n",
      "Epoch 110/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3284\n",
      "Epoch 111/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3283\n",
      "Epoch 112/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3275\n",
      "Epoch 113/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3270\n",
      "Epoch 114/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3276\n",
      "Epoch 115/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3262\n",
      "Epoch 116/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3263\n",
      "Epoch 117/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3266\n",
      "Epoch 118/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3259\n",
      "Epoch 119/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3252\n",
      "Epoch 120/150\n",
      "74098/74098 [==============================] - 21s 284us/sample - loss: 0.3254\n",
      "Epoch 121/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3247\n",
      "Epoch 122/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3243\n",
      "Epoch 123/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3246\n",
      "Epoch 124/150\n",
      "74098/74098 [==============================] - 21s 290us/sample - loss: 0.3243\n",
      "Epoch 125/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3239\n",
      "Epoch 126/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3229\n",
      "Epoch 127/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3260\n",
      "Epoch 128/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3326\n",
      "Epoch 129/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3304\n",
      "Epoch 130/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3275\n",
      "Epoch 131/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3233\n",
      "Epoch 132/150\n",
      "74098/74098 [==============================] - 21s 280us/sample - loss: 0.3220\n",
      "Epoch 133/150\n",
      "74098/74098 [==============================] - 22s 290us/sample - loss: 0.3225\n",
      "Epoch 134/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3215\n",
      "Epoch 135/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3214\n",
      "Epoch 136/150\n",
      "74098/74098 [==============================] - 22s 294us/sample - loss: 0.3208\n",
      "Epoch 137/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3200\n",
      "Epoch 138/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3206\n",
      "Epoch 139/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3198\n",
      "Epoch 140/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3199\n",
      "Epoch 141/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3190\n",
      "Epoch 142/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3189\n",
      "Epoch 143/150\n",
      "74098/74098 [==============================] - 22s 293us/sample - loss: 0.3194\n",
      "Epoch 144/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3180\n",
      "Epoch 145/150\n",
      "74098/74098 [==============================] - 21s 289us/sample - loss: 0.3187\n",
      "Epoch 146/150\n",
      "74098/74098 [==============================] - 22s 291us/sample - loss: 0.3179\n",
      "Epoch 147/150\n",
      "74098/74098 [==============================] - 21s 287us/sample - loss: 0.3175\n",
      "Epoch 148/150\n",
      "74098/74098 [==============================] - 21s 288us/sample - loss: 0.3176\n",
      "Epoch 149/150\n",
      "74098/74098 [==============================] - 21s 285us/sample - loss: 0.3168\n",
      "Epoch 150/150\n",
      "74098/74098 [==============================] - 21s 286us/sample - loss: 0.3168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7f39ff588>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul.fit(X_train_sc, Y_train_en, epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "74098/74098 [==============================] - 56s 755us/sample - loss: 7.1540\n",
      "Epoch 2/150\n",
      "74098/74098 [==============================] - 59s 797us/sample - loss: 7.1540\n",
      "Epoch 3/150\n",
      "74098/74098 [==============================] - 59s 797us/sample - loss: 7.1540\n",
      "Epoch 4/150\n",
      "74098/74098 [==============================] - 59s 795us/sample - loss: 7.1540\n",
      "Epoch 5/150\n",
      "74098/74098 [==============================] - 56s 757us/sample - loss: 7.1540\n",
      "Epoch 6/150\n",
      "74098/74098 [==============================] - 43s 584us/sample - loss: 7.1540\n",
      "Epoch 7/150\n",
      "74098/74098 [==============================] - 51s 687us/sample - loss: 7.1540\n",
      "Epoch 8/150\n",
      "74098/74098 [==============================] - 54s 725us/sample - loss: 7.1540\n",
      "Epoch 9/150\n",
      "74098/74098 [==============================] - 50s 676us/sample - loss: 7.1540\n",
      "Epoch 10/150\n",
      "74098/74098 [==============================] - 52s 701us/sample - loss: 7.1540\n",
      "Epoch 11/150\n",
      "74098/74098 [==============================] - 61s 820us/sample - loss: 7.1540\n",
      "Epoch 12/150\n",
      "74098/74098 [==============================] - 58s 785us/sample - loss: 7.1540\n",
      "Epoch 13/150\n",
      "74098/74098 [==============================] - 57s 775us/sample - loss: 7.1540\n",
      "Epoch 14/150\n",
      "74098/74098 [==============================] - 53s 712us/sample - loss: 7.1540\n",
      "Epoch 15/150\n",
      "74098/74098 [==============================] - 58s 785us/sample - loss: 7.1540\n",
      "Epoch 16/150\n",
      "74098/74098 [==============================] - 62s 843us/sample - loss: 7.1540\n",
      "Epoch 17/150\n",
      "74098/74098 [==============================] - 60s 813us/sample - loss: 7.1540\n",
      "Epoch 18/150\n",
      "74098/74098 [==============================] - 53s 722us/sample - loss: 7.1540\n",
      "Epoch 19/150\n",
      "74098/74098 [==============================] - 57s 765us/sample - loss: 7.1540\n",
      "Epoch 20/150\n",
      "74098/74098 [==============================] - 62s 831us/sample - loss: 7.1540\n",
      "Epoch 21/150\n",
      "74098/74098 [==============================] - 62s 831us/sample - loss: 7.1540\n",
      "Epoch 22/150\n",
      "74098/74098 [==============================] - 58s 780us/sample - loss: 7.1540\n",
      "Epoch 23/150\n",
      "74098/74098 [==============================] - 54s 731us/sample - loss: 7.1540\n",
      "Epoch 24/150\n",
      "74098/74098 [==============================] - 57s 764us/sample - loss: 7.1540\n",
      "Epoch 25/150\n",
      "74098/74098 [==============================] - 55s 741us/sample - loss: 7.1540\n",
      "Epoch 26/150\n",
      "74098/74098 [==============================] - 52s 708us/sample - loss: 7.1540\n",
      "Epoch 27/150\n",
      "74098/74098 [==============================] - 52s 699us/sample - loss: 7.1540\n",
      "Epoch 28/150\n",
      "74098/74098 [==============================] - 59s 795us/sample - loss: 7.1540\n",
      "Epoch 29/150\n",
      "74098/74098 [==============================] - 57s 774us/sample - loss: 7.1540\n",
      "Epoch 30/150\n",
      "74098/74098 [==============================] - 50s 674us/sample - loss: 7.1540\n",
      "Epoch 31/150\n",
      "74098/74098 [==============================] - 55s 741us/sample - loss: 7.1540\n",
      "Epoch 32/150\n",
      "74098/74098 [==============================] - 56s 761us/sample - loss: 7.1540\n",
      "Epoch 33/150\n",
      "74098/74098 [==============================] - 52s 708us/sample - loss: 7.1540\n",
      "Epoch 34/150\n",
      "74098/74098 [==============================] - 46s 620us/sample - loss: 7.1540\n",
      "Epoch 35/150\n",
      "74098/74098 [==============================] - 56s 758us/sample - loss: 7.1540\n",
      "Epoch 36/150\n",
      "74098/74098 [==============================] - 55s 748us/sample - loss: 7.1540\n",
      "Epoch 37/150\n",
      "74098/74098 [==============================] - 48s 644us/sample - loss: 7.1540\n",
      "Epoch 38/150\n",
      "74098/74098 [==============================] - 51s 685us/sample - loss: 7.1540\n",
      "Epoch 39/150\n",
      "74098/74098 [==============================] - 57s 767us/sample - loss: 7.1540\n",
      "Epoch 40/150\n",
      "74098/74098 [==============================] - 55s 742us/sample - loss: 7.1540\n",
      "Epoch 41/150\n",
      "74098/74098 [==============================] - 46s 620us/sample - loss: 7.1540\n",
      "Epoch 42/150\n",
      "74098/74098 [==============================] - 53s 721us/sample - loss: 7.1540\n",
      "Epoch 43/150\n",
      "74098/74098 [==============================] - 56s 757us/sample - loss: 7.1540\n",
      "Epoch 44/150\n",
      "74098/74098 [==============================] - 48s 647us/sample - loss: 7.1540\n",
      "Epoch 45/150\n",
      "74098/74098 [==============================] - 56s 752us/sample - loss: 7.1540\n",
      "Epoch 46/150\n",
      "74098/74098 [==============================] - 54s 734us/sample - loss: 7.1540\n",
      "Epoch 47/150\n",
      "74098/74098 [==============================] - 49s 656us/sample - loss: 7.1540\n",
      "Epoch 48/150\n",
      "74098/74098 [==============================] - 50s 679us/sample - loss: 7.1540\n",
      "Epoch 49/150\n",
      "74098/74098 [==============================] - 31s 417us/sample - loss: 7.1540\n",
      "Epoch 50/150\n",
      "74098/74098 [==============================] - 28s 376us/sample - loss: 7.1540\n",
      "Epoch 51/150\n",
      "74098/74098 [==============================] - 28s 373us/sample - loss: 7.1540\n",
      "Epoch 52/150\n",
      "74098/74098 [==============================] - 26s 353us/sample - loss: 7.1540\n",
      "Epoch 53/150\n",
      "74098/74098 [==============================] - 24s 321us/sample - loss: 7.1540\n",
      "Epoch 54/150\n",
      "74098/74098 [==============================] - 26s 351us/sample - loss: 7.1540\n",
      "Epoch 55/150\n",
      "74098/74098 [==============================] - 26s 354us/sample - loss: 7.1540\n",
      "Epoch 56/150\n",
      "74098/74098 [==============================] - 26s 345us/sample - loss: 7.1540\n",
      "Epoch 57/150\n",
      "74098/74098 [==============================] - 25s 344us/sample - loss: 7.1540\n",
      "Epoch 58/150\n",
      "74098/74098 [==============================] - 27s 363us/sample - loss: 7.1540\n",
      "Epoch 59/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 60/150\n",
      "74098/74098 [==============================] - 28s 381us/sample - loss: 7.1540\n",
      "Epoch 61/150\n",
      "74098/74098 [==============================] - 25s 341us/sample - loss: 7.1540\n",
      "Epoch 62/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 63/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 64/150\n",
      "74098/74098 [==============================] - 27s 364us/sample - loss: 7.1540\n",
      "Epoch 65/150\n",
      "74098/74098 [==============================] - 26s 356us/sample - loss: 7.1540\n",
      "Epoch 66/150\n",
      "74098/74098 [==============================] - 25s 340us/sample - loss: 7.1540\n",
      "Epoch 67/150\n",
      "74098/74098 [==============================] - 27s 368us/sample - loss: 7.1540\n",
      "Epoch 68/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 7.1540\n",
      "Epoch 69/150\n",
      "74098/74098 [==============================] - 28s 371us/sample - loss: 7.1540\n",
      "Epoch 70/150\n",
      "74098/74098 [==============================] - 25s 342us/sample - loss: 7.1540\n",
      "Epoch 71/150\n",
      "74098/74098 [==============================] - 27s 369us/sample - loss: 7.1540\n",
      "Epoch 72/150\n",
      "74098/74098 [==============================] - 26s 346us/sample - loss: 7.1540\n",
      "Epoch 73/150\n",
      "74098/74098 [==============================] - 22s 299us/sample - loss: 7.1540\n",
      "Epoch 74/150\n",
      "74098/74098 [==============================] - 24s 330us/sample - loss: 7.1540\n",
      "Epoch 75/150\n",
      "74098/74098 [==============================] - 29s 387us/sample - loss: 7.1540\n",
      "Epoch 76/150\n",
      "74098/74098 [==============================] - 28s 379us/sample - loss: 7.1540\n",
      "Epoch 77/150\n",
      "74098/74098 [==============================] - 27s 364us/sample - loss: 7.1540\n",
      "Epoch 78/150\n",
      "74098/74098 [==============================] - 25s 331us/sample - loss: 7.1540\n",
      "Epoch 79/150\n",
      "74098/74098 [==============================] - 27s 365us/sample - loss: 7.1540\n",
      "Epoch 80/150\n",
      "74098/74098 [==============================] - 26s 357us/sample - loss: 7.1540\n",
      "Epoch 81/150\n",
      "74098/74098 [==============================] - 27s 364us/sample - loss: 7.1540\n",
      "Epoch 82/150\n",
      "74098/74098 [==============================] - 26s 352us/sample - loss: 7.1540\n",
      "Epoch 83/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 84/150\n",
      "74098/74098 [==============================] - 28s 377us/sample - loss: 7.1540\n",
      "Epoch 85/150\n",
      "74098/74098 [==============================] - 28s 380us/sample - loss: 7.1540\n",
      "Epoch 86/150\n",
      "74098/74098 [==============================] - 27s 371us/sample - loss: 7.1540\n",
      "Epoch 87/150\n",
      "74098/74098 [==============================] - 28s 376us/sample - loss: 7.1540\n",
      "Epoch 88/150\n",
      "74098/74098 [==============================] - 27s 361us/sample - loss: 7.1540\n",
      "Epoch 89/150\n",
      "74098/74098 [==============================] - 28s 377us/sample - loss: 7.1540\n",
      "Epoch 90/150\n",
      "74098/74098 [==============================] - 29s 388us/sample - loss: 7.1540\n",
      "Epoch 91/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 92/150\n",
      "74098/74098 [==============================] - 28s 375us/sample - loss: 7.1540\n",
      "Epoch 93/150\n",
      "74098/74098 [==============================] - 27s 367us/sample - loss: 7.1540\n",
      "Epoch 94/150\n",
      "74098/74098 [==============================] - 29s 395us/sample - loss: 7.1540\n",
      "Epoch 95/150\n",
      "74098/74098 [==============================] - 26s 357us/sample - loss: 7.1540\n",
      "Epoch 96/150\n",
      "74098/74098 [==============================] - 28s 373us/sample - loss: 7.1540\n",
      "Epoch 97/150\n",
      "74098/74098 [==============================] - 28s 380us/sample - loss: 7.1540\n",
      "Epoch 98/150\n",
      "74098/74098 [==============================] - 28s 381us/sample - loss: 7.1540\n",
      "Epoch 99/150\n",
      "74098/74098 [==============================] - 28s 376us/sample - loss: 7.1540\n",
      "Epoch 100/150\n",
      "74098/74098 [==============================] - 30s 400us/sample - loss: 7.1540\n",
      "Epoch 101/150\n",
      "74098/74098 [==============================] - 30s 401us/sample - loss: 7.1540\n",
      "Epoch 102/150\n",
      "74098/74098 [==============================] - 28s 383us/sample - loss: 7.1540\n",
      "Epoch 103/150\n",
      "74098/74098 [==============================] - 27s 368us/sample - loss: 7.1540\n",
      "Epoch 104/150\n",
      "74098/74098 [==============================] - 26s 346us/sample - loss: 7.1540\n",
      "Epoch 105/150\n",
      "74098/74098 [==============================] - 26s 352us/sample - loss: 7.1540\n",
      "Epoch 106/150\n",
      "74098/74098 [==============================] - 31s 418us/sample - loss: 7.1540\n",
      "Epoch 107/150\n",
      "74098/74098 [==============================] - 33s 452us/sample - loss: 7.1540\n",
      "Epoch 108/150\n",
      "74098/74098 [==============================] - 27s 371us/sample - loss: 7.1540\n",
      "Epoch 109/150\n",
      "74098/74098 [==============================] - 28s 380us/sample - loss: 7.1540\n",
      "Epoch 110/150\n",
      "74098/74098 [==============================] - 28s 382us/sample - loss: 7.1540\n",
      "Epoch 111/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 7.1540\n",
      "Epoch 112/150\n",
      "74098/74098 [==============================] - 28s 373us/sample - loss: 7.1540\n",
      "Epoch 113/150\n",
      "74098/74098 [==============================] - 25s 341us/sample - loss: 7.1540\n",
      "Epoch 114/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 7.1540\n",
      "Epoch 115/150\n",
      "74098/74098 [==============================] - 26s 348us/sample - loss: 7.1540\n",
      "Epoch 116/150\n",
      "74098/74098 [==============================] - 27s 370us/sample - loss: 7.1540\n",
      "Epoch 117/150\n",
      "74098/74098 [==============================] - 27s 359us/sample - loss: 7.1540\n",
      "Epoch 118/150\n",
      "74098/74098 [==============================] - 27s 365us/sample - loss: 7.1540\n",
      "Epoch 119/150\n",
      "74098/74098 [==============================] - 29s 386us/sample - loss: 7.1540\n",
      "Epoch 120/150\n",
      "74098/74098 [==============================] - 26s 348us/sample - loss: 7.1540\n",
      "Epoch 121/150\n",
      "74098/74098 [==============================] - 27s 368us/sample - loss: 7.1540\n",
      "Epoch 122/150\n",
      "74098/74098 [==============================] - 25s 336us/sample - loss: 7.1540\n",
      "Epoch 123/150\n",
      "74098/74098 [==============================] - 27s 363us/sample - loss: 7.1540\n",
      "Epoch 124/150\n",
      "74098/74098 [==============================] - 27s 366us/sample - loss: 7.1540\n",
      "Epoch 125/150\n",
      "74098/74098 [==============================] - 28s 384us/sample - loss: 7.1540\n",
      "Epoch 126/150\n",
      "74098/74098 [==============================] - 27s 366us/sample - loss: 7.1540\n",
      "Epoch 127/150\n",
      "74098/74098 [==============================] - 25s 344us/sample - loss: 7.1540\n",
      "Epoch 128/150\n",
      "74098/74098 [==============================] - 24s 328us/sample - loss: 7.1540\n",
      "Epoch 129/150\n",
      "74098/74098 [==============================] - 26s 352us/sample - loss: 7.1540\n",
      "Epoch 130/150\n",
      "74098/74098 [==============================] - 24s 325us/sample - loss: 7.1540\n",
      "Epoch 131/150\n",
      "74098/74098 [==============================] - 26s 356us/sample - loss: 7.1540\n",
      "Epoch 132/150\n",
      "74098/74098 [==============================] - 25s 335us/sample - loss: 7.1540\n",
      "Epoch 133/150\n",
      "74098/74098 [==============================] - 25s 333us/sample - loss: 7.1540\n",
      "Epoch 134/150\n",
      "74098/74098 [==============================] - 25s 340us/sample - loss: 7.1540\n",
      "Epoch 135/150\n",
      "74098/74098 [==============================] - 25s 343us/sample - loss: 7.1540\n",
      "Epoch 136/150\n",
      "74098/74098 [==============================] - 24s 328us/sample - loss: 7.1540\n",
      "Epoch 137/150\n",
      "74098/74098 [==============================] - 26s 355us/sample - loss: 7.1540\n",
      "Epoch 138/150\n",
      "74098/74098 [==============================] - 26s 344us/sample - loss: 7.1540\n",
      "Epoch 139/150\n",
      "74098/74098 [==============================] - 25s 336us/sample - loss: 7.1540\n",
      "Epoch 140/150\n",
      "74098/74098 [==============================] - 25s 341us/sample - loss: 7.1540\n",
      "Epoch 141/150\n",
      "74098/74098 [==============================] - 25s 339us/sample - loss: 7.1540\n",
      "Epoch 142/150\n",
      "74098/74098 [==============================] - 24s 323us/sample - loss: 7.1540\n",
      "Epoch 143/150\n",
      "74098/74098 [==============================] - 24s 326us/sample - loss: 7.1540\n",
      "Epoch 144/150\n",
      "74098/74098 [==============================] - 25s 335us/sample - loss: 7.1540\n",
      "Epoch 145/150\n",
      "74098/74098 [==============================] - 23s 317us/sample - loss: 7.1540\n",
      "Epoch 146/150\n",
      "74098/74098 [==============================] - 25s 331us/sample - loss: 7.1540\n",
      "Epoch 147/150\n",
      "74098/74098 [==============================] - 26s 346us/sample - loss: 7.1540\n",
      "Epoch 148/150\n",
      "74098/74098 [==============================] - 25s 337us/sample - loss: 7.1540\n",
      "Epoch 149/150\n",
      "74098/74098 [==============================] - 26s 350us/sample - loss: 7.1540\n",
      "Epoch 150/150\n",
      "74098/74098 [==============================] - 28s 374us/sample - loss: 7.1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7a680dcc0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMul_b.fit(X_train_sc_b, Y_train_en_b, epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 6, ..., 5, 3, 5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul = modelMul.predict_classes(X_test_sc)\n",
    "predMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prédiction sur l'échantillon test\n",
    "predMul_b = modelMul_b.predict_classes(X_test_sc_b)\n",
    "predMul_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656788923973767\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,predMul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5446927374301676\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en_b,predMul_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00220967 0.03670513 0.50282347 0.72943776 0.78296096\n",
      " 0.94230297 0.99987724 1.        ] 0\n",
      "[0.         0.00207824 0.03643032 0.50036675 0.72579462 0.77897311\n",
      " 0.94046455 0.9997555  1.        ] 1\n",
      "[0.         0.00217725 0.03765369 0.52215676 0.75768443 0.81262807\n",
      " 0.96516393 0.99974385 1.        ] 2\n",
      "[0.         0.00211119 0.04025334 0.56988037 0.82843068 0.88684025\n",
      " 0.95862069 0.99985925 1.        ] 3\n",
      "[0.         0.00209479 0.03836083 0.5236973  0.76525268 0.77441739\n",
      " 0.93964389 0.99973815 1.        ] 4\n",
      "[0.         0.0028222  0.0468799  0.64142364 0.64581373 0.71354657\n",
      " 0.92521167 0.99968642 1.        ] 5\n",
      "[0.         0.00330396 0.06255507 0.10242291 0.50770925 0.59669604\n",
      " 0.89251101 0.99955947 1.        ] 6\n",
      "[0.         0.00228629 0.00685888 0.48532961 0.71980185 0.77467293\n",
      " 0.94068335 0.99974597 1.        ] 7\n",
      "[0.         0.00121832 0.03472222 0.49658869 0.72124756 0.77424464\n",
      " 0.94054581 0.99975634 1.        ] 8\n",
      "[0.         0.00218712 0.0363305  0.49769137 0.7218712  0.77484812\n",
      " 0.94070474 0.99975699 1.        ] 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes=10\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_en, predMul,pos_label=i)\n",
    "    print(fpr[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# data to plot\n",
    "n_groups = 4\n",
    "accuracy_MC = (0.81, 0.85, 0.86, 0.44)\n",
    "accuracy_BC = (0.920, 0.96, 0.97,0.54)\n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, accuracy_MC, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='multi-class classification')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, accuracy_BC, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Binary classification')\n",
    "\n",
    "plt.xlabel('Number neurones/ hidden couches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy MLP for both classification')\n",
    "plt.xticks(index + bar_width, ('0/0', '165/3', '287/3', '526/9'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr O/O:  0.06588423579621232\n",
      "fpr 165/3:  0.018138170178714323\n",
      "fpr 287/3:  0.022672712723392906\n",
      "fpr 526/9:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test_en_b, predSimple_b).ravel()\n",
    "fpr=fp/(fp+tn)\n",
    "print(\"fpr O/O: \",fpr)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test_en_b, predMul_b).ravel()\n",
    "fpr=fp/(fp+tn)\n",
    "print(\"fpr 165/3: \",fpr)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test_en_b, predMul50_b).ravel()\n",
    "fpr=fp/(fp+tn)\n",
    "print(\"fpr 287/3: \",fpr)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test_en_b, predMul75_b).ravel()\n",
    "fpr=fp/(fp+tn)\n",
    "print(\"fpr 526/9: \",fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups = 4\n",
    "fpr = (0.065, 0.018, 0.022,1.0)\n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, fpr, bar_width,\n",
    "alpha=opacity,\n",
    "color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('Number neurones/ hidden couches')\n",
    "plt.ylabel('False positive rate')\n",
    "plt.title('Evaluation FPR MLP')\n",
    "plt.xticks(index + bar_width, ('0/0', '165/3', '287/3', '526/9'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-173ecce5ffc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.add(\n\u001b[1;32m      8\u001b[0m     Embedding(input_dim=190,\n\u001b[0;32m----> 9\u001b[0;31m               \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_length' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(\n",
    "    Embedding(input_dim=190,\n",
    "              input_length = training_length,\n",
    "              output_dim=10,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False,\n",
    "              mask_zero=True))\n",
    "\n",
    "# Masking layer for pre-trained embeddings\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, return_sequences=False, \n",
    "               dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "parameters = {'solver': ['lbfgs', 'sgd', 'adam'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9],'learning_rate' : ['constant', 'invscaling', 'adaptive'],'learning_rate_init':10.0 ** -np.arange(1, 10),'early_stopping':[True]}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_sc, Y_train_en)\n",
    "print(clf.score(X_train_sc, Y_train_en))\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.predict(X_test_sc)\n",
    "              \n",
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "parameters = {'solver': [ 'adam'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9],'learning_rate_init':10.0 ** -np.arange(1, 10),'early_stopping':[True]}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_sc, Y_train_en)\n",
    "print(clf.score(X_train_sc, Y_train_en))\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.predict(X_test_sc)\n",
    "              \n",
    "#taux de succès\n",
    "print(metrics.accuracy_score(Y_test_en,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
